{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d575c626",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d2049a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "active_passive = pd.read_csv(r\"C:\\Users\\amnsh\\OneDrive\\Desktop\\NLP Lab\\Datasets\\Act_Pas\\active_passive.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ced8abed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and preprocess the sentences\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def preprocess_text(text):\n",
    "    doc = nlp(text)\n",
    "    return \" \".join([token.lemma_ for token in doc])\n",
    "\n",
    "active_passive['Active_processed'] = active_passive['Active'].apply(preprocess_text)\n",
    "active_passive['Passive_processed'] = active_passive['Passive'].apply(preprocess_text)\n",
    "\n",
    "# Concatenate processed sentences and labels separately\n",
    "X = active_passive['Active_processed'].tolist() + active_passive['Passive_processed'].tolist()\n",
    "y = ['Active'] * len(active_passive) + ['Passive'] * len(active_passive)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3faa772d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction using TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d429145d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_voice_dependency(sentence):\n",
    "  doc = nlp(sentence)\n",
    "\n",
    "  # Check if passive auxiliary verb is present with a past participle\n",
    "  for token in doc:\n",
    "    if token.pos_ == \"AUX\" and token.dep_ == \"auxpass\" and token.head.pos_ == \"VERB\":\n",
    "      return \"Passive\"\n",
    "\n",
    "  # Check for \"be\" verbs with past participle indicating passive voice\n",
    "  for token in doc:\n",
    "    if token.lemma_ in [\"be\", \"am\", \"is\", \"are\", \"was\", \"were\", \"been\"] and token.dep_ == \"cop\" and token.head.pos_ == \"VERB\":\n",
    "      return \"Passive\"\n",
    "  \n",
    "  return \"Active\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ac3ada6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_voice(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    passive_indicators = [\"is\", \"am\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\"]\n",
    "    \n",
    "    for token in doc:\n",
    "        if token.text.lower() in passive_indicators and token.dep_ == \"aux\":\n",
    "            print(\"Passive indicator:\", token.text.lower(), \"Dependency:\", token.dep_)\n",
    "            return \"Passive\"\n",
    "    \n",
    "    return \"Active\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7da5abc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_sentence(sentence):\n",
    "  predicted_voice = identify_voice(sentence)\n",
    "  if predicted_voice == 'Active':\n",
    "    # Search for the processed passive sentence in the Passive_processed column\n",
    "    matching_row = active_passive.loc[active_passive['Passive_processed'] == preprocess_text(sentence), 'Active']\n",
    "  else:\n",
    "    # Search for the processed active sentence in the Active_processed column\n",
    "    matching_row = active_passive.loc[active_passive['Active_processed'] == preprocess_text(sentence), 'Passive']\n",
    "\n",
    "  if len(matching_row) > 0:\n",
    "    return matching_row.iloc[0]\n",
    "  else:\n",
    "    return sentence  # Return the original sentence if no match is found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e4510289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation function using dependency parsing\n",
    "def transform_to_opposite_voice(sentence):\n",
    "    predicted_voice = identify_voice(sentence)\n",
    "    if predicted_voice == 'Active':\n",
    "        return transform_sentence(sentence)\n",
    "    else:\n",
    "        return transform_sentence(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6746a0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Voice: Active\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "user_input = \"The cat chased the mouse.\"\n",
    "predicted_voice = identify_voice_dependency(user_input)\n",
    "print(\"Predicted Voice:\", predicted_voice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6f1c2be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sentence: The teacher reject the project.\n",
      "Transformed Sentence: project is rejected by teacher\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from collections import defaultdict\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "def identify_voice_dependency(sentence):\n",
    "  doc = nlp(sentence)\n",
    "  passive_aux_verbs = [\"be\", \"am\", \"is\", \"are\", \"was\", \"were\", \"been\"]\n",
    "\n",
    "  # Check for passive auxiliary verb with past participle\n",
    "  for token in doc:\n",
    "    if token.pos_ == \"AUX\" and token.dep_ == \"auxpass\" and token.head.pos_ == \"VERB\":\n",
    "      return \"Passive\"\n",
    "\n",
    "  # Check for \"be\" verbs with past participle indicating passive voice\n",
    "  for token in doc:\n",
    "    if token.lemma_ in passive_aux_verbs and token.dep_ == \"cop\" and token.head.pos_ == \"VERB\":\n",
    "      return \"Passive\"\n",
    "\n",
    "  return \"Active\"\n",
    "\n",
    "\n",
    "def transform_to_opposite_voice(sentence):\n",
    "  predicted_voice = identify_voice_dependency(sentence)\n",
    "  doc = nlp(sentence)\n",
    "\n",
    "  if predicted_voice == 'Active':\n",
    "    # Active to Passive Transformation\n",
    "\n",
    "    # Find the subject and object\n",
    "    subject = None\n",
    "    object = None\n",
    "    for token in doc:\n",
    "      if token.dep_ == \"nsubj\":\n",
    "        subject = token.text\n",
    "      elif token.dep_ == \"dobj\":\n",
    "        object = token.text\n",
    "\n",
    "    if subject and object:\n",
    "      # Replace verb with past participle (assuming simple active voice)\n",
    "      verb = [token.text for token in doc if token.pos_ == \"VERB\"][0]\n",
    "      passive_verb = f\"{verb}ed\"\n",
    "      return f\"{object} is {passive_verb} by {subject}\"  # Simple passive structure\n",
    "    else:\n",
    "      return sentence  # Could not identify subject-object for transformation\n",
    "\n",
    "  else:\n",
    "    # Passive to Active Transformation (assuming simple passive structure)\n",
    "\n",
    "    aux_verb = None\n",
    "    past_participle = None\n",
    "    subject = None  # Might need adjustment based on sentence structure\n",
    "\n",
    "    for token in doc:\n",
    "      if token.pos_ == \"AUX\" and token.dep_ == \"auxpass\":\n",
    "        aux_verb = token.text\n",
    "      elif token.dep_ == \"pcomp\" and token.pos_ == \"VERB\":  # Assuming past participle\n",
    "        past_participle = token.text\n",
    "      elif token.dep_ == \"nsubjpass\":  # Passive subject (agent)\n",
    "        subject = token.text\n",
    "\n",
    "    if aux_verb and past_participle:\n",
    "      verb = past_participle.rstrip(\"ed\")  # Remove \"ed\" from past participle\n",
    "      return f\"{subject} {aux_verb.replace('be', 'beens')} {verb}\"  # Handle \"be\" verbs appropriately\n",
    "    else:\n",
    "      return sentence  # Could not identify necessary elements for transformation\n",
    "\n",
    "\n",
    "user_input = \"The teacher reject the project.\"\n",
    "transformed_sentence = transform_to_opposite_voice(user_input)\n",
    "print(\"Original Sentence:\", user_input)\n",
    "print(\"Transformed Sentence:\", transformed_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25510a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
