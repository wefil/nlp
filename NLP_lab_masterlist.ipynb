{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 1:Spell Check**\n",
        "\n",
        "**Identify the list of candidate words using Trie structure for the misspelled word. Find the minimum\n",
        "edit distance and choose the correct word based on the context.\n",
        "INPUT:\n",
        "\"During the summer we have the best ueather.\", \"I have a black ueather jacket, so nice.\"\n",
        "OUTPUT:\n",
        "\"During the summer we have the best weather.\", \"I have a black leather jacket, so nice.\"\n",
        "Use the developed model to choose the correct spellings for the following sentences:**\n",
        "1. Mr Patrick is our new (principle/principal).\n",
        "2. The company (excepted/accepted) all the terms.\n",
        "3. Please don’t keep your dog on the (lose/loose).\n",
        "4. The (later/latter) is my best friend.\n",
        "5. I need some (stationary/stationery) products for my craftwork.\n",
        "6. The actor (excepted/accepted) the Oscar.\n",
        "7. I will call you (later/latter) in the evening.\n",
        "8. Covid (affects/effects) the lungs.\n",
        "9. The (council/counsel) of the ministers were sworn in yesterday.\n",
        "10. Robert (too/to) wants to accompany us to the park.\n",
        "11. Mia will (council/counsel) me about choosing fashion as my career.\n",
        "12. The (bear/bare) at the zoo was very playful.\n",
        "13. The sheep have a lot of (fur/far) that keeps them warm.\n",
        "14. The hot spring is at the (furthest/ farthest) corner of the street.\n",
        "15. Can you (advice/advise) me on how to study for exams?\n",
        "16. The team will (loose/lose) the match if they don’t play well.\n",
        "17. Can you go (to/too) the market for me?\n",
        "18. The teachers asked the students to keep (quite/quiet).\n",
        "19. The (heap/hip) of garbage should be cleaned immediately.\n",
        "20. This is (there/their) house."
      ],
      "metadata": {
        "id": "lY4Eu1mMqseA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vIsJb9lnq5Bm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 2: Sentiment Analysis Dataset**"
      ],
      "metadata": {
        "id": "981S8UwiOE9_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Task:\n",
        "*  Explain the pipeline for developing sentiment analysis task.\n",
        "*  Perform cleaning and preprocessing of text.\n",
        "*  Generate representations using:\n",
        "*  Bag of Words\n",
        "*  TF-IDF\n",
        "*  Continuous Bag of Words\n",
        "*  Skip gram\n",
        "*  Word2Vec.\n",
        "\n",
        "1.  Classify the data using appropriate machine learning techniques to generate labels.\n",
        "2.  Analyze the labels and explain the impact of embedding techniques in misclassification.\n",
        "3.  Discuss the limitations of each embedding technique and explain the techniques that rectify it.**\n",
        "\n",
        "Input:\n",
        "What is not to like about this product.\n",
        "Not bad.\n",
        "Not an issue.\n",
        "Not buggy.\n",
        "Not happy.\n",
        "Not user-friendly.\n",
        "Not good.\n",
        "Is it any good?\n",
        "I do not dislike horror movies.\n",
        "Disliking horror movies is not uncommon.\n",
        "Sometimes I really hate the show.\n",
        "I love having to wait two months for the next series to come out!\n",
        "The final episode was surprising with a terrible twist at the end.\n",
        "The film was easy to watch but I would not recommend it to my friends.\n",
        "I LOL’d at the end of the cake scene"
      ],
      "metadata": {
        "id": "4OKvq5L-rrTb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "5DkVj52Orrk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('/content/train.csv', encoding='latin1')\n",
        "test_df = pd.read_csv('/content/test.csv', encoding='latin1')"
      ],
      "metadata": {
        "id": "2jV9rhcYOC6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.shape\n",
        "train_df.info()\n",
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "id": "ss_T0Kv2PMYv",
        "outputId": "3e4ae973-ea90-4c11-e9ae-7c4134700a23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 27481 entries, 0 to 27480\n",
            "Data columns (total 10 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   textID            27481 non-null  object \n",
            " 1   text              27480 non-null  object \n",
            " 2   selected_text     27480 non-null  object \n",
            " 3   sentiment         27481 non-null  object \n",
            " 4   Time of Tweet     27481 non-null  object \n",
            " 5   Age of User       27481 non-null  object \n",
            " 6   Country           27481 non-null  object \n",
            " 7   Population -2020  27481 non-null  int64  \n",
            " 8   Land Area (Km²)   27481 non-null  float64\n",
            " 9   Density (P/Km²)   27481 non-null  int64  \n",
            "dtypes: float64(1), int64(2), object(7)\n",
            "memory usage: 2.1+ MB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       textID                                               text  \\\n",
              "0  cb774db0d1                I`d have responded, if I were going   \n",
              "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
              "2  088c60f138                          my boss is bullying me...   \n",
              "3  9642c003ef                     what interview! leave me alone   \n",
              "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
              "\n",
              "                         selected_text sentiment Time of Tweet Age of User  \\\n",
              "0  I`d have responded, if I were going   neutral       morning        0-20   \n",
              "1                             Sooo SAD  negative          noon       21-30   \n",
              "2                          bullying me  negative         night       31-45   \n",
              "3                       leave me alone  negative       morning       46-60   \n",
              "4                        Sons of ****,  negative          noon       60-70   \n",
              "\n",
              "       Country  Population -2020  Land Area (Km²)  Density (P/Km²)  \n",
              "0  Afghanistan          38928346         652860.0               60  \n",
              "1      Albania           2877797          27400.0              105  \n",
              "2      Algeria          43851044        2381740.0               18  \n",
              "3      Andorra             77265            470.0              164  \n",
              "4       Angola          32866272        1246700.0               26  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-92d1c068-ad86-4362-8711-a0797b846412\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>textID</th>\n",
              "      <th>text</th>\n",
              "      <th>selected_text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>Time of Tweet</th>\n",
              "      <th>Age of User</th>\n",
              "      <th>Country</th>\n",
              "      <th>Population -2020</th>\n",
              "      <th>Land Area (Km²)</th>\n",
              "      <th>Density (P/Km²)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cb774db0d1</td>\n",
              "      <td>I`d have responded, if I were going</td>\n",
              "      <td>I`d have responded, if I were going</td>\n",
              "      <td>neutral</td>\n",
              "      <td>morning</td>\n",
              "      <td>0-20</td>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>38928346</td>\n",
              "      <td>652860.0</td>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>549e992a42</td>\n",
              "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
              "      <td>Sooo SAD</td>\n",
              "      <td>negative</td>\n",
              "      <td>noon</td>\n",
              "      <td>21-30</td>\n",
              "      <td>Albania</td>\n",
              "      <td>2877797</td>\n",
              "      <td>27400.0</td>\n",
              "      <td>105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>088c60f138</td>\n",
              "      <td>my boss is bullying me...</td>\n",
              "      <td>bullying me</td>\n",
              "      <td>negative</td>\n",
              "      <td>night</td>\n",
              "      <td>31-45</td>\n",
              "      <td>Algeria</td>\n",
              "      <td>43851044</td>\n",
              "      <td>2381740.0</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9642c003ef</td>\n",
              "      <td>what interview! leave me alone</td>\n",
              "      <td>leave me alone</td>\n",
              "      <td>negative</td>\n",
              "      <td>morning</td>\n",
              "      <td>46-60</td>\n",
              "      <td>Andorra</td>\n",
              "      <td>77265</td>\n",
              "      <td>470.0</td>\n",
              "      <td>164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>358bd9e861</td>\n",
              "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
              "      <td>Sons of ****,</td>\n",
              "      <td>negative</td>\n",
              "      <td>noon</td>\n",
              "      <td>60-70</td>\n",
              "      <td>Angola</td>\n",
              "      <td>32866272</td>\n",
              "      <td>1246700.0</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-92d1c068-ad86-4362-8711-a0797b846412')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-92d1c068-ad86-4362-8711-a0797b846412 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-92d1c068-ad86-4362-8711-a0797b846412');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f7bfc21b-426d-498d-8759-7ae790783e4e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f7bfc21b-426d-498d-8759-7ae790783e4e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f7bfc21b-426d-498d-8759-7ae790783e4e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df",
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 27481,\n  \"fields\": [\n    {\n      \"column\": \"textID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 27481,\n        \"samples\": [\n          \"a7f72a928a\",\n          \"ef42dee96c\",\n          \"07d17131b1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 27480,\n        \"samples\": [\n          \" Enjoy! Family trumps everything\",\n          \" --of them kinda turns me off of it all.  And then I buy more of them and dig a deeper hole, etc. ;;\",\n          \"Clive it`s my birthday pat me  http://apps.facebook.com/dogbook/profile/view/6386106\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"selected_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 22430,\n        \"samples\": [\n          \"that is why I drive a (teeny tiny) honda civic\",\n          \"Sorry...but, I bet they aren`t that bad...\",\n          \"yummy\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"neutral\",\n          \"negative\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Time of Tweet\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"morning\",\n          \"noon\",\n          \"night\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age of User\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"0-20\",\n          \"21-30\",\n          \"70-100\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Country\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 195,\n        \"samples\": [\n          \"Philippines\",\n          \"Belgium\",\n          \"Sierra Leone\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Population -2020\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 150494590,\n        \"min\": 801,\n        \"max\": 1439323776,\n        \"num_unique_values\": 195,\n        \"samples\": [\n          109581078,\n          11589623,\n          7976983\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Land Area (Km\\u00b2)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1807424.6900064738,\n        \"min\": 0.0,\n        \"max\": 16376870.0,\n        \"num_unique_values\": 193,\n        \"samples\": [\n          2267050.0,\n          1280000.0,\n          100250.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Density (P/Km\\u00b2)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2013,\n        \"min\": 2,\n        \"max\": 26337,\n        \"num_unique_values\": 136,\n        \"samples\": [\n          400,\n          71,\n          331\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove unneccessary columns\n",
        "\n",
        "columns_to_remove = ['textID','Time of Tweet', 'Age of User', 'Country', 'Population -2020', 'Land Area (Km²)', 'Density (P/Km²)']\n",
        "train_df = train_df.drop(columns=columns_to_remove)"
      ],
      "metadata": {
        "id": "NdMAQBBXcU-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = train_df.dropna()"
      ],
      "metadata": {
        "id": "vMjWZaidPWQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRtZrS3ZdYZF",
        "outputId": "27f97827-69d4-4f8a-a337-45fdc8d1ed9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 27480 entries, 0 to 27480\n",
            "Data columns (total 3 columns):\n",
            " #   Column         Non-Null Count  Dtype \n",
            "---  ------         --------------  ----- \n",
            " 0   text           27480 non-null  object\n",
            " 1   selected_text  27480 non-null  object\n",
            " 2   sentiment      27480 non-null  object\n",
            "dtypes: object(3)\n",
            "memory usage: 858.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.shape\n",
        "test_df.info()\n",
        "test_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        },
        "id": "h2BULnP8Pa89",
        "outputId": "aeb789a0-05cc-45e0-9d0a-76c0ff22b292"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4815 entries, 0 to 4814\n",
            "Data columns (total 9 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   textID            3534 non-null   object \n",
            " 1   text              3534 non-null   object \n",
            " 2   sentiment         3534 non-null   object \n",
            " 3   Time of Tweet     3534 non-null   object \n",
            " 4   Age of User       3534 non-null   object \n",
            " 5   Country           3534 non-null   object \n",
            " 6   Population -2020  3534 non-null   float64\n",
            " 7   Land Area (Km²)   3534 non-null   float64\n",
            " 8   Density (P/Km²)   3534 non-null   float64\n",
            "dtypes: float64(3), object(6)\n",
            "memory usage: 338.7+ KB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       textID                                               text sentiment  \\\n",
              "0  f87dea47db  Last session of the day  http://twitpic.com/67ezh   neutral   \n",
              "1  96d74cb729   Shanghai is also really exciting (precisely -...  positive   \n",
              "2  eee518ae67  Recession hit Veronique Branquinho, she has to...  negative   \n",
              "3  01082688c6                                        happy bday!  positive   \n",
              "4  33987a8ee5             http://twitpic.com/4w75p - I like it!!  positive   \n",
              "\n",
              "  Time of Tweet Age of User      Country  Population -2020  Land Area (Km²)  \\\n",
              "0       morning        0-20  Afghanistan        38928346.0         652860.0   \n",
              "1          noon       21-30      Albania         2877797.0          27400.0   \n",
              "2         night       31-45      Algeria        43851044.0        2381740.0   \n",
              "3       morning       46-60      Andorra           77265.0            470.0   \n",
              "4          noon       60-70       Angola        32866272.0        1246700.0   \n",
              "\n",
              "   Density (P/Km²)  \n",
              "0             60.0  \n",
              "1            105.0  \n",
              "2             18.0  \n",
              "3            164.0  \n",
              "4             26.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7bf30fa1-6eff-4f08-82bd-592ad5972e1d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>textID</th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>Time of Tweet</th>\n",
              "      <th>Age of User</th>\n",
              "      <th>Country</th>\n",
              "      <th>Population -2020</th>\n",
              "      <th>Land Area (Km²)</th>\n",
              "      <th>Density (P/Km²)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>f87dea47db</td>\n",
              "      <td>Last session of the day  http://twitpic.com/67ezh</td>\n",
              "      <td>neutral</td>\n",
              "      <td>morning</td>\n",
              "      <td>0-20</td>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>38928346.0</td>\n",
              "      <td>652860.0</td>\n",
              "      <td>60.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>96d74cb729</td>\n",
              "      <td>Shanghai is also really exciting (precisely -...</td>\n",
              "      <td>positive</td>\n",
              "      <td>noon</td>\n",
              "      <td>21-30</td>\n",
              "      <td>Albania</td>\n",
              "      <td>2877797.0</td>\n",
              "      <td>27400.0</td>\n",
              "      <td>105.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>eee518ae67</td>\n",
              "      <td>Recession hit Veronique Branquinho, she has to...</td>\n",
              "      <td>negative</td>\n",
              "      <td>night</td>\n",
              "      <td>31-45</td>\n",
              "      <td>Algeria</td>\n",
              "      <td>43851044.0</td>\n",
              "      <td>2381740.0</td>\n",
              "      <td>18.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>01082688c6</td>\n",
              "      <td>happy bday!</td>\n",
              "      <td>positive</td>\n",
              "      <td>morning</td>\n",
              "      <td>46-60</td>\n",
              "      <td>Andorra</td>\n",
              "      <td>77265.0</td>\n",
              "      <td>470.0</td>\n",
              "      <td>164.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>33987a8ee5</td>\n",
              "      <td>http://twitpic.com/4w75p - I like it!!</td>\n",
              "      <td>positive</td>\n",
              "      <td>noon</td>\n",
              "      <td>60-70</td>\n",
              "      <td>Angola</td>\n",
              "      <td>32866272.0</td>\n",
              "      <td>1246700.0</td>\n",
              "      <td>26.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7bf30fa1-6eff-4f08-82bd-592ad5972e1d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7bf30fa1-6eff-4f08-82bd-592ad5972e1d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7bf30fa1-6eff-4f08-82bd-592ad5972e1d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-635e69f9-ec68-4ffc-bce9-da3b0164d99b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-635e69f9-ec68-4ffc-bce9-da3b0164d99b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-635e69f9-ec68-4ffc-bce9-da3b0164d99b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_df",
              "summary": "{\n  \"name\": \"test_df\",\n  \"rows\": 4815,\n  \"fields\": [\n    {\n      \"column\": \"textID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3534,\n        \"samples\": [\n          \"142108215\",\n          \"fb08563a7b\",\n          \"9a2c6ae21c\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3534,\n        \"samples\": [\n          \" Thank you so much phaoloo !!!!\",\n          \"Midnight ice-cream weather! So **** bored\",\n          \"Ohh i forgot to tell you last night that when i was a alton towers i touched a shark  it was amazing !!!! it was nt a massive one tho\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"neutral\",\n          \"positive\",\n          \"negative\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Time of Tweet\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"morning\",\n          \"noon\",\n          \"night\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age of User\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"0-20\",\n          \"21-30\",\n          \"70-100\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Country\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 195,\n        \"samples\": [\n          \"Philippines\",\n          \"Belgium\",\n          \"Sierra Leone\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Population -2020\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 146875664.3624433,\n        \"min\": 801.0,\n        \"max\": 1439323776.0,\n        \"num_unique_values\": 195,\n        \"samples\": [\n          109581078.0,\n          11589623.0,\n          7976983.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Land Area (Km\\u00b2)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1839133.9114273796,\n        \"min\": 0.0,\n        \"max\": 16376870.0,\n        \"num_unique_values\": 193,\n        \"samples\": [\n          2267050.0,\n          1280000.0,\n          100250.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Density (P/Km\\u00b2)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1967.0123670106411,\n        \"min\": 2.0,\n        \"max\": 26337.0,\n        \"num_unique_values\": 136,\n        \"samples\": [\n          400.0,\n          71.0,\n          331.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_remove = ['textID','Time of Tweet', 'Age of User', 'Country', 'Population -2020', 'Land Area (Km²)', 'Density (P/Km²)']\n",
        "test_df = test_df.drop(columns=columns_to_remove)"
      ],
      "metadata": {
        "id": "4f4ukGdYPwAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKPts-HgdewM",
        "outputId": "904fbc56-619b-4299-ccbc-75505f3cb0ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4815 entries, 0 to 4814\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   text       3534 non-null   object\n",
            " 1   sentiment  3534 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 75.4+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "\n",
        "# Handle missing values in the sentiment column\n",
        "train_df = train_df.dropna(subset=[\"sentiment\"])\n",
        "test_df = test_df.dropna(subset=[\"sentiment\"])\n",
        "\n",
        "# Initialize LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "# Fit and transform labels in the training dataset\n",
        "train_y = encoder.fit_transform(train_df[\"sentiment\"])\n",
        "test_y = encoder.transform(test_df[\"sentiment\"])"
      ],
      "metadata": {
        "id": "t5a0hjFdegmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Cleaning and Preprocessing"
      ],
      "metadata": {
        "id": "ME4jmxTfesm9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dz0WAlU7gi-B",
        "outputId": "fe6cf43c-096b-4a7d-dd3d-a29242791b82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pKiS0iEgmhb",
        "outputId": "e4601512-ce56-4b77-be3c-8c678e81cf90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yhkgt6dfgqAz",
        "outputId": "dd41dc16-0277-42eb-a2d8-cfad486f178b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "def pre_processing(tweet: str):\n",
        "    # Remove Leading Blank Spaces\n",
        "    tweet = tweet.strip()\n",
        "\n",
        "    # Lower Case\n",
        "    tweet = tweet.lower()\n",
        "\n",
        "    # Remove URLS\n",
        "    url_pattern = re.compile(r\"https?://\\S+|www\\.\\S+\")\n",
        "    tweet = re.sub(url_pattern, \"\", tweet)\n",
        "\n",
        "    # Remove UserName\n",
        "    username_pattern = re.compile(r\"@\\w+\")\n",
        "    tweet = re.sub(username_pattern, \"\", tweet)\n",
        "\n",
        "    # Remove Hashtags\n",
        "    hashtag_pattern = re.compile(r\"#\\w+\")\n",
        "    tweet = re.sub(hashtag_pattern, \"\", tweet)\n",
        "\n",
        "    # Character normalization // todaaaaay -> today\n",
        "    tweet = re.sub(r\"([a-zA-Z])\\1{2,}\", r'\\1', tweet)\n",
        "\n",
        "    # Remove Special Characters\n",
        "    tweet = re.sub(r'[^a-zA-Z\\s]', \"\", tweet)\n",
        "\n",
        "    # Word Tokenizer\n",
        "    tweet = nltk.word_tokenize(tweet)\n",
        "\n",
        "    # Lemmatization and Part-of-Speech tagging\n",
        "    def get_pos(word):\n",
        "        tag = nltk.pos_tag([word])[0][1][0].upper()\n",
        "        tag_dict = {\"N\": \"n\", \"V\": \"v\", \"R\": \"r\", \"J\": \"a\"}\n",
        "        return tag_dict.get(tag, \"n\")\n",
        "\n",
        "    lemma = WordNetLemmatizer()\n",
        "    tweet = [lemma.lemmatize(word, pos=get_pos(word)) for word in tweet]\n",
        "\n",
        "    return tweet\n",
        "\n",
        "# Example usage of pre_processing function\n",
        "processed_tweet = pre_processing(\"I loveeeee NLP, @apple_apple, www.apple_x.com, #NLP \")\n",
        "print(processed_tweet)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNGrTpjGev7S",
        "outputId": "c2bba34f-8aa6-4f03-e164-db456ba10d88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'love', 'nlp']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df[\"pre-tweet\"] = train_df[\"text\"].apply(pre_processing)\n",
        "test_df[\"pre-tweet\"] = test_df[\"text\"].apply(pre_processing)\n",
        "\n",
        "train_df[\"documents\"] = train_df[\"pre-tweet\"].apply(lambda x : \" \".join(x))\n",
        "test_df[\"documents\"] = test_df[\"pre-tweet\"].apply(lambda x : \" \".join(x))\n",
        "\n",
        "\n",
        "\n",
        "vocab = set()\n",
        "\n",
        "for words in train_df[\"pre-tweet\"]:\n",
        "    for word in words:\n",
        "        vocab.add(word)\n",
        "\n",
        "print(\"Vocab Size :\", len(vocab))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKdXnHuBg8TT",
        "outputId": "78bf6ade-b92e-454b-de3f-1f7431068614"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab Size : 22037\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate representations using:\n",
        "• Bag of Words\n",
        "• TF-IDF\n",
        "• Continuous Bag of Words\n",
        "• Skip gram\n",
        "• Word2Vec."
      ],
      "metadata": {
        "id": "YKJNJpkthWwT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bag of Words"
      ],
      "metadata": {
        "id": "kp6Pp2QNhemT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "bag_of_words = CountVectorizer()\n",
        "\n",
        "train_bow = bag_of_words.fit_transform(train_df[\"documents\"])\n",
        "test_bow = bag_of_words.transform(test_df[\"documents\"])\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model = LogisticRegression(max_iter = 1000)\n",
        "model.fit(train_bow, train_y)\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "predict = model.predict(test_bow)\n",
        "print(\"Accuracy Score :\", accuracy_score(test_y, predict), end='\\n\\n')\n",
        "print(classification_report(y_true = test_y, y_pred = predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aciWflZqhcAr",
        "outputId": "84877720-00b5-4bab-c4d7-7b49f8005712"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score : 0.7023203169213356\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.64      0.67      1001\n",
            "           1       0.64      0.73      0.68      1430\n",
            "           2       0.79      0.72      0.75      1103\n",
            "\n",
            "    accuracy                           0.70      3534\n",
            "   macro avg       0.71      0.70      0.70      3534\n",
            "weighted avg       0.71      0.70      0.70      3534\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tf-Idf"
      ],
      "metadata": {
        "id": "I6dGmBJrhs0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tf_idf = TfidfVectorizer()\n",
        "\n",
        "train_idf = tf_idf.fit_transform(train_df[\"documents\"])\n",
        "test_idf = tf_idf.transform(test_df[\"documents\"])\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model = LogisticRegression(max_iter = 1000)\n",
        "model.fit(train_idf, train_y)\n",
        "\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "predict = model.predict(test_idf)\n",
        "print(\"Accuracy Score :\", accuracy_score(test_y, predict), end='\\n\\n')\n",
        "print(classification_report(y_true = test_y, y_pred = predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPvJr9uThu7T",
        "outputId": "c25ef2d4-066f-418f-ee22-99d6e34e916f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score : 0.7105263157894737\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.65      0.69      1001\n",
            "           1       0.64      0.75      0.69      1430\n",
            "           2       0.81      0.71      0.76      1103\n",
            "\n",
            "    accuracy                           0.71      3534\n",
            "   macro avg       0.73      0.70      0.71      3534\n",
            "weighted avg       0.72      0.71      0.71      3534\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CBOW"
      ],
      "metadata": {
        "id": "u2sM4kcciBzr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "g_model = Word2Vec(sentences=train_df[\"pre-tweet\"], vector_size=200, window=5, workers=5, epochs=500)\n",
        "def in_vocab(word_l):\n",
        "    for word in word_l:\n",
        "        if word not in g_model.wv:\n",
        "            return False\n",
        "    else:\n",
        "        return True\n",
        "\n",
        "train_vec = [g_model.wv[x].sum(axis = 0) if len(x) and in_vocab(x) else np.zeros((200)) for x in train_df[\"pre-tweet\"]]\n",
        "test_vec  = [g_model.wv[x].sum(axis = 0) if len(x) and in_vocab(x) else np.zeros((200)) for x in test_df[\"pre-tweet\"]]\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model = LogisticRegression(max_iter = 1000)\n",
        "model.fit(train_vec, train_y)\n",
        "\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "predict = model.predict(test_vec)\n",
        "print(\"Accuracy Score :\", accuracy_score(test_y, predict), end='\\n\\n')\n",
        "print(classification_report(y_true = test_y, y_pred = predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlkyIttCiCBM",
        "outputId": "af7b1f89-2395-425e-d46f-9e6fc4a1062b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score : 0.5249009620826259\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.29      0.40      1001\n",
            "           1       0.47      0.86      0.60      1430\n",
            "           2       0.74      0.30      0.43      1103\n",
            "\n",
            "    accuracy                           0.52      3534\n",
            "   macro avg       0.62      0.48      0.48      3534\n",
            "weighted avg       0.61      0.52      0.49      3534\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Skip gram"
      ],
      "metadata": {
        "id": "myja6xInjAez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "g_model = Word2Vec(sentences=train_df[\"pre-tweet\"], vector_size=200, window=5, workers=5, sg=1, epochs=500)\n",
        "def in_vocab(word_l):\n",
        "    for word in word_l:\n",
        "        if word not in g_model.wv:\n",
        "            return False\n",
        "    else:\n",
        "        return True\n",
        "\n",
        "train_vec = [g_model.wv[x].sum(axis = 0) if len(x) and in_vocab(x) else np.zeros((200)) for x in train_df[\"pre-tweet\"]]\n",
        "test_vec  = [g_model.wv[x].sum(axis = 0) if len(x) and in_vocab(x) else np.zeros((200)) for x in test_df[\"pre-tweet\"]]\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model = LogisticRegression(max_iter = 1000)\n",
        "model.fit(train_vec, train_y)\n",
        "\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "predict = model.predict(test_vec)\n",
        "print(\"Accuracy Score :\", accuracy_score(test_y, predict), end='\\n\\n')\n",
        "print(classification_report(y_true = test_y, y_pred = predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "zslSC-V8jB67",
        "outputId": "025de95e-b65a-4df2-fd23-eb1b2aecb489"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-c4507d5b71ec>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mg_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pre-tweet\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0min_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_l\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_l\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sentences, corpus_file, vector_size, alpha, window, min_count, max_vocab_size, sample, seed, workers, min_alpha, sg, hs, negative, ns_exponent, cbow_mean, hashfxn, epochs, null_word, trim_rule, sorted_vocab, batch_words, compute_loss, callbacks, comment, max_final_vocab, shrink_windows)\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_corpus_sanity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             self.train(\n\u001b[0m\u001b[1;32m    431\u001b[0m                 \u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m                 \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_total_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, corpus_iterable, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m   1071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcorpus_iterable\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1073\u001b[0;31m                 trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch = self._train_epoch(\n\u001b[0m\u001b[1;32m   1074\u001b[0m                     \u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcur_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m                     \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mqueue_factor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport_delay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreport_delay\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36m_train_epoch\u001b[0;34m(self, data_iterable, cur_epoch, total_examples, total_words, queue_factor, report_delay, callbacks)\u001b[0m\n\u001b[1;32m   1432\u001b[0m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1434\u001b[0;31m         trained_word_count, raw_word_count, job_tally = self._log_epoch_progress(\n\u001b[0m\u001b[1;32m   1435\u001b[0m             \u001b[0mprogress_queue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_queue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcur_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1436\u001b[0m             \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport_delay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreport_delay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_corpus_file_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36m_log_epoch_progress\u001b[0;34m(self, progress_queue, job_queue, cur_epoch, total_examples, total_words, report_delay, is_corpus_file_mode)\u001b[0m\n\u001b[1;32m   1287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0munfinished_worker_count\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1289\u001b[0;31m             \u001b[0mreport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprogress_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# blocks if workers too slow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1290\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreport\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# a thread reporting that it finished\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m                 \u001b[0munfinished_worker_count\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word2vec"
      ],
      "metadata": {
        "id": "z1mlg3HPkYhj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "model = api.load(\"glove-twitter-200\")\n",
        "\n",
        "shape_n = 200\n",
        "\n",
        "def in_vocab(word_l):\n",
        "    for word in word_l:\n",
        "        if word not in model:\n",
        "            return False\n",
        "    else:\n",
        "        return True\n",
        "\n",
        "train_vec = [model[x].sum(axis = 0) if len(x) and in_vocab(x) else np.zeros((shape_n)) for x in train_df[\"pre-tweet\"]]\n",
        "test_vec  = [model[x].sum(axis = 0) if len(x) and in_vocab(x) else np.zeros((shape_n)) for x in test_df[\"pre-tweet\"]]\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model = LogisticRegression(max_iter = 1000)\n",
        "model.fit(train_vec, train_y)\n",
        "\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "predict = model.predict(test_vec)\n",
        "print(\"Accuracy Score :\", accuracy_score(test_y, predict), end='\\n\\n')\n",
        "print(classification_report(y_true = test_y, y_pred = predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElWMHZOMkYED",
        "outputId": "65773735-a376-484b-a0fd-71fd36b574e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 758.5/758.5MB downloaded\n",
            "Accuracy Score : 0.642331635540464\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.56      0.63      1001\n",
            "           1       0.57      0.73      0.64      1430\n",
            "           2       0.73      0.60      0.66      1103\n",
            "\n",
            "    accuracy                           0.64      3534\n",
            "   macro avg       0.67      0.63      0.64      3534\n",
            "weighted avg       0.66      0.64      0.64      3534\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "text = \"\"\"What is not to like about this product.\n",
        "Not bad.\n",
        "Not an issue.\n",
        "Not buggy.\n",
        "Not happy.\n",
        "Not user-friendly.\n",
        "Not good.\n",
        "Is it any good?\n",
        "I do not dislike horror movies.\n",
        "Disliking horror movies is not uncommon.\n",
        "Sometimes I really hate the show.\n",
        "I love having to wait two months for the next series to come out!\n",
        "The final episode was surprising with a terrible twist at the end.\n",
        "The film was easy to watch but I would not recommend it to my friends.\n",
        "I LOL’d at the end of the cake scene.\"\"\"\n",
        "\n",
        "input_text = text.split(\"\\n\")\n",
        "input_text = [\" \".join(pre_processing(string)) for string in input_text]\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tf_idf = TfidfVectorizer()\n",
        "\n",
        "train_idf = tf_idf.fit_transform(train_df[\"documents\"])\n",
        "pred_idf = tf_idf.transform(input_text)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model = LogisticRegression(max_iter = 1000)\n",
        "model.fit(train_idf, train_y)\n",
        "\n",
        "predict = model.predict(pred_idf)\n",
        "predict = encoder.inverse_transform(predict)\n",
        "for index, text in enumerate(text.split(\"\\n\")):\n",
        "    print(text, \" : \", predict[index])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qcx6KJVgklZq",
        "outputId": "d45a316a-f107-4363-8d8f-5f27d37a0e88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is not to like about this product.  :  negative\n",
            "Not bad.  :  negative\n",
            "Not an issue.  :  negative\n",
            "Not buggy.  :  neutral\n",
            "Not happy.  :  positive\n",
            "Not user-friendly.  :  negative\n",
            "Not good.  :  positive\n",
            "Is it any good?  :  positive\n",
            "I do not dislike horror movies.   :  negative\n",
            "Disliking horror movies is not uncommon.   :  negative\n",
            "Sometimes I really hate the show.   :  negative\n",
            "I love having to wait two months for the next series to come out!   :  positive\n",
            "The final episode was surprising with a terrible twist at the end.  :  neutral\n",
            "The film was easy to watch but I would not recommend it to my friends.   :  neutral\n",
            "I LOL’d at the end of the cake scene.  :  neutral\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ex 3 :Application: Extractive Text Summarization**"
      ],
      "metadata": {
        "id": "xUaXmBCNt-Mc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Task:\n",
        "▪ Explain the pipeline for summarizing an input document by identifying informative sentences.\n",
        "▪ Perform cleaning and preprocessing of text.\n",
        "▪ Generate representations using:\n",
        "• Bag of Words\n",
        "• TF-IDF\n",
        "• Continuous Bag of Words\n",
        "• Skip gram\n",
        "• Word2Vec.\n",
        "• GloVe\n",
        "• FastText\n",
        "▪ Generate representations for each sentence using the above word embedding techniques.\n",
        "▪ Identify the distance between each sentence. Evaluate if semantically similar sentences lie\n",
        "closer to each other.\n",
        "▪ Explain the impact of embedding techniques in identifying the distance between sentences.\n",
        "▪ Which Embedding technique generates contextual representations? Justify."
      ],
      "metadata": {
        "id": "zNyZblist-gj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-I8E2JPOnUP",
        "outputId": "741138b3-6ab3-47b6-943e-cf585869192e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "def pre_processing(text):\n",
        "\n",
        "    # text to sentence\n",
        "    tokenized = sent_tokenize(text)\n",
        "\n",
        "    # Remove Punctuation\n",
        "    # Lower Case\n",
        "    # Strip White Spaces\n",
        "    pattern   = re.compile(r'[^a-zA-Z0-9\\s]')\n",
        "    tokenized = [pattern.sub('', sent).strip().lower() for sent in tokenized]\n",
        "\n",
        "    return tokenized\n",
        "\n",
        "corpus = []\n",
        "for doc in data:\n",
        "    corpus.extend(pre_processing(doc))\n",
        "\n",
        "print(\"Number of Sentences in Corpus : \", len(corpus))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "SBb_EuNmP98f",
        "outputId": "7d0efa00-1a50-4e5d-ff7a-af6598cdd32b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-ca7061dbf211>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3KUQ38TARnll"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KN39Tm41Rn4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 4**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YJ3hxeTGoFCn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Application: Hate Speech Identification\n",
        "Dataset: Download the dataset from Hate Speech and Offensive Language Dataset (kaggle.com)\n",
        "Task:\n",
        "▪ Explain the pipeline for developing sentiment analysis task.\n",
        "▪ Perform cleaning and preprocessing of text.\n",
        "▪ Generate representations using:\n",
        "• Word2Vec\n",
        "• Fasttext\n",
        "• CNN.\n",
        "• RNN\n",
        "▪ Feed the representations as input to appropriate classification technique.\n",
        "▪ Evaluate the accuracy of each model and analyze the labels that are misclassified."
      ],
      "metadata": {
        "id": "kDFYM2GpoIW-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Library\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "dnxB8GX5oK6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import *\n"
      ],
      "metadata": {
        "id": "dGuqP-zLrIrv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(r'/content/Hate speech.csv')"
      ],
      "metadata": {
        "id": "bSLOo6exqnPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "OTBof10Fqngf",
        "outputId": "fcfd9250-f6b8-4da3-d8b8-138322ce1604"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
              "0           0      3            0                   0        3      2   \n",
              "1           1      3            0                   3        0      1   \n",
              "2           2      3            0                   3        0      1   \n",
              "3           3      3            0                   2        1      1   \n",
              "4           4      6            0                   6        0      1   \n",
              "\n",
              "                                               tweet  \n",
              "0  !!! RT @mayasolovely: As a woman you shouldn't...  \n",
              "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
              "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
              "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
              "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e3bb5534-61e4-4911-91dc-bc235067eebe\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>count</th>\n",
              "      <th>hate_speech</th>\n",
              "      <th>offensive_language</th>\n",
              "      <th>neither</th>\n",
              "      <th>class</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e3bb5534-61e4-4911-91dc-bc235067eebe')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e3bb5534-61e4-4911-91dc-bc235067eebe button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e3bb5534-61e4-4911-91dc-bc235067eebe');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-be34b9c7-5523-44dc-b63c-656cd1ea7e26\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-be34b9c7-5523-44dc-b63c-656cd1ea7e26')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-be34b9c7-5523-44dc-b63c-656cd1ea7e26 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 24783,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7299,\n        \"min\": 0,\n        \"max\": 25296,\n        \"num_unique_values\": 24783,\n        \"samples\": [\n          2326,\n          16283,\n          19362\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 3,\n        \"max\": 9,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          6,\n          7,\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hate_speech\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 7,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          1,\n          6,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"offensive_language\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 9,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          8,\n          3,\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"neither\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 9,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          8,\n          0,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2,\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tweet\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 24783,\n        \"samples\": [\n          \"934 8616\\ni got a missed call from yo bitch\",\n          \"RT @KINGTUNCHI_: Fucking with a bad bitch you gone need some money lil homie!\",\n          \"RT @eanahS__: @1inkkofrosess lol my credit ain't no where near good , but I know the right man for the job .. that ho nice though!\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data[['tweet','class']]"
      ],
      "metadata": {
        "id": "2KPM_uDuqnu-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnctgzoHqn-9",
        "outputId": "69d02f22-af81-416e-d4df-45062adbbe49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 24783 entries, 0 to 24782\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   tweet   24783 non-null  object\n",
            " 1   class   24783 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 387.4+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install emoji\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERmsdlgo0M5n",
        "outputId": "76980e50-a373-410d-e747-62ba9c695d8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: emoji in /usr/local/lib/python3.10/dist-packages (2.11.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "import emoji\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "tokenizer = TweetTokenizer()\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrDTygmnxAgX",
        "outputId": "526841cd-e914-4330-f9f7-d671e4174824"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_tweet(tweet):\n",
        "    tokens = tokenizer.tokenize(tweet)\n",
        "    tokens = [token.lower() for token in tokens]\n",
        "    tokens = [re.sub(r'https?://\\S+|www\\.\\S+', '', token) for token in tokens]\n",
        "    tokens = [re.sub(r'\\W', ' ', token) for token in tokens if token.isalnum()]\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    tokens = [emoji.demojize(token) for token in tokens]\n",
        "    contractions = {\n",
        "        \"can't\": \"cannot\",\n",
        "        \"won't\": \"will not\",\n",
        "    }\n",
        "    tokens = [contractions[token] if token in contractions else token for token in tokens]\n",
        "    tokens = [token for token in tokens if not token.startswith('@')]\n",
        "    processed_tweet = ' '.join(tokens)\n",
        "\n",
        "    return processed_tweet\n"
      ],
      "metadata": {
        "id": "ehB7BSBqzPNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess_tweet(\"@Dia jsut poseted someting (*)@(*$)(*)#@)!!! Im screaming ^U^😃\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "YSBpQ20jzVz-",
        "outputId": "a5d879c3-8fc1-48f4-c692-5ba6f30f96ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'jsut poseted someting im screaming u'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['pre_process_tweet'] = data['tweet'].apply(preprocess_tweet)"
      ],
      "metadata": {
        "id": "MOsTA7G-1_Qj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6S36nTO2F-6",
        "outputId": "9ba7dda4-d9d6-4cee-9951-411b07af1f1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 24783 entries, 0 to 24782\n",
            "Data columns (total 3 columns):\n",
            " #   Column             Non-Null Count  Dtype \n",
            "---  ------             --------------  ----- \n",
            " 0   tweet              24783 non-null  object\n",
            " 1   class              24783 non-null  int64 \n",
            " 2   pre_process_tweet  24783 non-null  object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 581.0+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "_b7pjrXo2drx",
        "outputId": "8d4529b4-2115-4e52-d075-400fcacc073a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               tweet  class  \\\n",
              "0  !!! RT @mayasolovely: As a woman you shouldn't...      2   \n",
              "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...      1   \n",
              "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...      1   \n",
              "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...      1   \n",
              "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...      1   \n",
              "\n",
              "                                   pre_process_tweet  \n",
              "0  rt woman complain cleaning house man always ta...  \n",
              "1  rt boy dat cold tyga dwn bad cuffin dat hoe 1s...  \n",
              "2  rt dawg rt 0sbaby4life ever fuck bitch start c...  \n",
              "3                                rt look like tranny  \n",
              "4  rt shit hear might true might faker bitch told ya  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-82e6dee5-b3aa-452f-98df-fee08fd5dd1c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>class</th>\n",
              "      <th>pre_process_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
              "      <td>2</td>\n",
              "      <td>rt woman complain cleaning house man always ta...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
              "      <td>1</td>\n",
              "      <td>rt boy dat cold tyga dwn bad cuffin dat hoe 1s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
              "      <td>1</td>\n",
              "      <td>rt dawg rt 0sbaby4life ever fuck bitch start c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
              "      <td>1</td>\n",
              "      <td>rt look like tranny</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
              "      <td>1</td>\n",
              "      <td>rt shit hear might true might faker bitch told ya</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-82e6dee5-b3aa-452f-98df-fee08fd5dd1c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-82e6dee5-b3aa-452f-98df-fee08fd5dd1c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-82e6dee5-b3aa-452f-98df-fee08fd5dd1c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d46783f9-2d79-42e7-a6a0-b6ee99d4dbb8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d46783f9-2d79-42e7-a6a0-b6ee99d4dbb8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d46783f9-2d79-42e7-a6a0-b6ee99d4dbb8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 24783,\n  \"fields\": [\n    {\n      \"column\": \"tweet\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 24783,\n        \"samples\": [\n          \"934 8616\\ni got a missed call from yo bitch\",\n          \"RT @KINGTUNCHI_: Fucking with a bad bitch you gone need some money lil homie!\",\n          \"RT @eanahS__: @1inkkofrosess lol my credit ain't no where near good , but I know the right man for the job .. that ho nice though!\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2,\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pre_process_tweet\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 23844,\n        \"samples\": [\n          \"shuddup hoe\",\n          \"rt awkward moment hold door someone use door next like bitch better back th\",\n          \"lol caitlyn carry 3 retard\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Generating representations\n",
        "\n",
        "#WordtoVec: Skipgram and CBOW\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "import numpy as np\n",
        "\n",
        "# Assuming cbow is already trained\n",
        "cbow = Word2Vec(data['pre_process_tweet'].values.tolist(), vector_size=100)\n",
        "\n",
        "def get_mean_vector(model, sentence, vocab):\n",
        "    words = [word for word in sentence if word in vocab]\n",
        "    if len(words) >= 1:\n",
        "        return np.mean(model.wv[words], axis=0)\n",
        "    return np.zeros((100,))\n",
        "\n",
        "vocab = cbow.wv.index_to_key\n",
        "\n",
        "cbow_array = []\n",
        "for sentence in data['pre_process_tweet'].values.tolist():\n",
        "    cbow_array.append(get_mean_vector(cbow, sentence, vocab))\n",
        "\n",
        "print(len(cbow_array))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VPX-6tZ2tVh",
        "outputId": "beba4e42-5a79-4fdc-f607-c732195e771e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24783\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "import numpy as np\n",
        "\n",
        "# Assuming skipgram is already trained\n",
        "skipgram = Word2Vec(data['pre_process_tweet'].values.tolist(), vector_size=100, sg=1)  # sg=1 specifies SkipGram\n",
        "\n",
        "def get_mean_vector(model, sentence, vocab):\n",
        "    words = [word for word in sentence if word in vocab]\n",
        "    if len(words) >= 1:\n",
        "        return np.mean(model.wv[words], axis=0)\n",
        "    return np.zeros((100,))\n",
        "\n",
        "vocab = skipgram.wv.index_to_key\n",
        "\n",
        "skipgram_array = []\n",
        "for sentence in data['pre_process_tweet'].values.tolist():\n",
        "    skipgram_array.append(get_mean_vector(skipgram, sentence, vocab))\n",
        "\n",
        "print(len(skipgram_array))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHalCfT3BNia",
        "outputId": "91f29fb9-0aee-4dae-a69d-232c195580e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24783\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "PAGwM9vhDeRi",
        "outputId": "4a412aea-f0ce-4838-eb81-e30396cc3705"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   tweet  class  \\\n",
              "0      !!! RT @mayasolovely: As a woman you shouldn't...      2   \n",
              "1      !!!!! RT @mleew17: boy dats cold...tyga dwn ba...      1   \n",
              "2      !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...      1   \n",
              "3      !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...      1   \n",
              "4      !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...      1   \n",
              "...                                                  ...    ...   \n",
              "24778  you's a muthaf***in lie &#8220;@LifeAsKing: @2...      1   \n",
              "24779  you've gone and broke the wrong heart baby, an...      2   \n",
              "24780  young buck wanna eat!!.. dat nigguh like I ain...      1   \n",
              "24781              youu got wild bitches tellin you lies      1   \n",
              "24782  ~~Ruffled | Ntac Eileen Dahlia - Beautiful col...      2   \n",
              "\n",
              "                                       pre_process_tweet  \n",
              "0      rt woman complain cleaning house man always ta...  \n",
              "1      rt boy dat cold tyga dwn bad cuffin dat hoe 1s...  \n",
              "2      rt dawg rt 0sbaby4life ever fuck bitch start c...  \n",
              "3                                    rt look like tranny  \n",
              "4      rt shit hear might true might faker bitch told ya  \n",
              "...                                                  ...  \n",
              "24778  muthaf lie right tl trash mine bible scripture...  \n",
              "24779    gone broke wrong heart baby drove redneck crazy  \n",
              "24780  young buck wanna eat dat nigguh like aint fuck...  \n",
              "24781                     youu got wild bitch tellin lie  \n",
              "24782  ruffled ntac eileen dahlia beautiful color com...  \n",
              "\n",
              "[24783 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-72f35fc8-3ff2-4822-9c40-1b12e6654299\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>class</th>\n",
              "      <th>pre_process_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
              "      <td>2</td>\n",
              "      <td>rt woman complain cleaning house man always ta...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
              "      <td>1</td>\n",
              "      <td>rt boy dat cold tyga dwn bad cuffin dat hoe 1s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
              "      <td>1</td>\n",
              "      <td>rt dawg rt 0sbaby4life ever fuck bitch start c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
              "      <td>1</td>\n",
              "      <td>rt look like tranny</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
              "      <td>1</td>\n",
              "      <td>rt shit hear might true might faker bitch told ya</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24778</th>\n",
              "      <td>you's a muthaf***in lie &amp;#8220;@LifeAsKing: @2...</td>\n",
              "      <td>1</td>\n",
              "      <td>muthaf lie right tl trash mine bible scripture...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24779</th>\n",
              "      <td>you've gone and broke the wrong heart baby, an...</td>\n",
              "      <td>2</td>\n",
              "      <td>gone broke wrong heart baby drove redneck crazy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24780</th>\n",
              "      <td>young buck wanna eat!!.. dat nigguh like I ain...</td>\n",
              "      <td>1</td>\n",
              "      <td>young buck wanna eat dat nigguh like aint fuck...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24781</th>\n",
              "      <td>youu got wild bitches tellin you lies</td>\n",
              "      <td>1</td>\n",
              "      <td>youu got wild bitch tellin lie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24782</th>\n",
              "      <td>~~Ruffled | Ntac Eileen Dahlia - Beautiful col...</td>\n",
              "      <td>2</td>\n",
              "      <td>ruffled ntac eileen dahlia beautiful color com...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>24783 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-72f35fc8-3ff2-4822-9c40-1b12e6654299')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-72f35fc8-3ff2-4822-9c40-1b12e6654299 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-72f35fc8-3ff2-4822-9c40-1b12e6654299');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-681cffa8-dc43-4831-a210-4e15d1d4e70c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-681cffa8-dc43-4831-a210-4e15d1d4e70c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-681cffa8-dc43-4831-a210-4e15d1d4e70c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_bdffb3cb-528c-415a-8951-db64f3a088be\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_bdffb3cb-528c-415a-8951-db64f3a088be button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 24783,\n  \"fields\": [\n    {\n      \"column\": \"tweet\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 24783,\n        \"samples\": [\n          \"934 8616\\ni got a missed call from yo bitch\",\n          \"RT @KINGTUNCHI_: Fucking with a bad bitch you gone need some money lil homie!\",\n          \"RT @eanahS__: @1inkkofrosess lol my credit ain't no where near good , but I know the right man for the job .. that ho nice though!\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2,\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pre_process_tweet\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 23844,\n        \"samples\": [\n          \"shuddup hoe\",\n          \"rt awkward moment hold door someone use door next like bitch better back th\",\n          \"lol caitlyn carry 3 retard\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tweets = data['pre_process_tweet'].values\n",
        "labels = data['class'].values\n",
        "\n",
        "#Tokenizing and Padding\n",
        "\n",
        "max_len = data['pre_process_tweet'].str.len().max()\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(tweets)\n",
        "sequences = tokenizer.texts_to_sequences(tweets)\n",
        "tweet_data = pad_sequences(sequences,maxlen=max_len)\n"
      ],
      "metadata": {
        "id": "zNWL1nBZEIP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Building\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "cnn_representation_dim = 100\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, cnn_representation_dim, input_length=max_len))\n",
        "model.add(Conv1D(128, 5, activation='relu'))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics= 'accuracy')\n",
        "model.fit(tweet_data, labels, epochs=10, batch_size=32, validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meKbljx_FcAX",
        "outputId": "56d54ac0-f0c0-4f30-b34b-fbcd3ef360e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "620/620 [==============================] - 39s 62ms/step - loss: 0.3439 - accuracy: 0.8773 - val_loss: 0.2513 - val_accuracy: 0.9161\n",
            "Epoch 2/10\n",
            "620/620 [==============================] - 38s 61ms/step - loss: 0.1949 - accuracy: 0.9284 - val_loss: 0.2959 - val_accuracy: 0.9030\n",
            "Epoch 3/10\n",
            "620/620 [==============================] - 37s 59ms/step - loss: 0.0933 - accuracy: 0.9670 - val_loss: 0.3330 - val_accuracy: 0.9042\n",
            "Epoch 4/10\n",
            "620/620 [==============================] - 43s 69ms/step - loss: 0.0489 - accuracy: 0.9838 - val_loss: 0.3790 - val_accuracy: 0.8973\n",
            "Epoch 5/10\n",
            "620/620 [==============================] - 36s 58ms/step - loss: 0.0332 - accuracy: 0.9886 - val_loss: 0.4543 - val_accuracy: 0.9074\n",
            "Epoch 6/10\n",
            "620/620 [==============================] - 36s 58ms/step - loss: 0.0252 - accuracy: 0.9914 - val_loss: 0.4508 - val_accuracy: 0.8880\n",
            "Epoch 7/10\n",
            "620/620 [==============================] - 38s 61ms/step - loss: 0.0208 - accuracy: 0.9921 - val_loss: 0.5586 - val_accuracy: 0.8993\n",
            "Epoch 8/10\n",
            "620/620 [==============================] - 36s 58ms/step - loss: 0.0196 - accuracy: 0.9926 - val_loss: 0.5722 - val_accuracy: 0.8971\n",
            "Epoch 9/10\n",
            "620/620 [==============================] - 36s 58ms/step - loss: 0.0170 - accuracy: 0.9930 - val_loss: 0.6039 - val_accuracy: 0.8830\n",
            "Epoch 10/10\n",
            "620/620 [==============================] - 36s 58ms/step - loss: 0.0180 - accuracy: 0.9924 - val_loss: 0.7188 - val_accuracy: 0.8933\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f59b19f93f0>"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_embeddings = model.layers[0].get_weights()[0]\n",
        "cnn_embeddings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75Wj9FJNGhHS",
        "outputId": "ce80241c-d75d-45d8-8bc4-c88ae0825fa5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.01696684, -0.00994224, -0.01948774, ..., -0.04631813,\n",
              "         0.00565956,  0.03472973],\n",
              "       [ 0.11805116,  0.17424363,  0.1470484 , ..., -0.04032356,\n",
              "        -0.09028555, -0.06763017],\n",
              "       [-0.00037258,  0.0233454 ,  0.03723885, ..., -0.02918104,\n",
              "         0.07457133,  0.0147731 ],\n",
              "       ...,\n",
              "       [-0.00192814,  0.00901241, -0.00971892, ...,  0.00437753,\n",
              "         0.00126193, -0.00257976],\n",
              "       [-0.02485954, -0.02839837, -0.04000815, ...,  0.00608123,\n",
              "        -0.00813431, -0.02873926],\n",
              "       [ 0.03607332, -0.02326905, -0.01823951, ..., -0.00224997,\n",
              "        -0.04690826, -0.0413673 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def train_and_evaluate_decision_tree(x_train, x_test, y_train, y_test, representation):\n",
        "    dtclassifier = DecisionTreeClassifier(random_state=9, max_depth=5)\n",
        "    dtclassifier.fit(x_train, y_train)\n",
        "    y_pred = dtclassifier.predict(x_test)\n",
        "    print(f\"\\nMetrics for {representation}:\")\n",
        "    print(f\"Model Score: {dtclassifier.score(x_train, y_train)}\")\n",
        "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "def get_dataset_prep(array, labels, test_size=0.2):  # Added default test_size\n",
        "    x_train, x_test, y_train, y_test = train_test_split(array, labels, test_size=test_size)\n",
        "    return x_train, x_test, y_train, y_test\n"
      ],
      "metadata": {
        "id": "3eKIRjkeIfZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test,y_train,y_test = get_dataset_prep(cbow_array,labels)\n",
        "train_and_evaluate_decision_tree(x_train, x_test, y_train, y_test, \"DT-CBOW\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JDJxGc_RMuN",
        "outputId": "25fce54f-ca33-4ea5-e626-07f2a5b5b932"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Metrics for DT-CBOW:\n",
            "Model Score: 0.7882578432361546\n",
            "Accuracy: 0.7700221908412346\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.03      0.05       312\n",
            "           1       0.80      0.95      0.87      3805\n",
            "           2       0.47      0.25      0.33       840\n",
            "\n",
            "    accuracy                           0.77      4957\n",
            "   macro avg       0.69      0.41      0.41      4957\n",
            "weighted avg       0.74      0.77      0.72      4957\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test,y_train,y_test = get_dataset_prep(skipgram_array,labels)\n",
        "train_and_evaluate_decision_tree(x_train, x_test, y_train, y_test, \"DT-Skip\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOvnHe4DRUFW",
        "outputId": "e4bcc5bb-0b85-4f8f-d24f-5243142e1ad0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Metrics for DT-Skip:\n",
            "Model Score: 0.7731261979219207\n",
            "Accuracy: 0.7837401654226347\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.39      0.03      0.05       272\n",
            "           1       0.79      1.00      0.88      3889\n",
            "           2       0.20      0.00      0.00       796\n",
            "\n",
            "    accuracy                           0.78      4957\n",
            "   macro avg       0.46      0.34      0.31      4957\n",
            "weighted avg       0.67      0.78      0.69      4957\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RNN representations\n",
        "from tensorflow.keras.layers import SimpleRNN  # Importing SimpleRNN from Keras\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "rnn_representation_dim = 100\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, rnn_representation_dim, input_length=max_len))\n",
        "model.add(SimpleRNN(32,return_sequences=False))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics = \"accuracy\")\n"
      ],
      "metadata": {
        "id": "WOhkIcWARYre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(tweet_data, labels, epochs=10, batch_size=32, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-zqPoAWRzPI",
        "outputId": "26b4027b-a060-4e0a-968c-cbdce1d02f22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "620/620 [==============================] - 36s 55ms/step - loss: 0.4093 - accuracy: 0.8556 - val_loss: 0.2752 - val_accuracy: 0.9098\n",
            "Epoch 2/10\n",
            "620/620 [==============================] - 36s 58ms/step - loss: 0.1966 - accuracy: 0.9303 - val_loss: 0.2895 - val_accuracy: 0.9038\n",
            "Epoch 3/10\n",
            "620/620 [==============================] - 31s 50ms/step - loss: 0.0837 - accuracy: 0.9721 - val_loss: 0.3845 - val_accuracy: 0.8925\n",
            "Epoch 4/10\n",
            "620/620 [==============================] - 33s 53ms/step - loss: 0.0453 - accuracy: 0.9848 - val_loss: 0.4555 - val_accuracy: 0.8804\n",
            "Epoch 5/10\n",
            "620/620 [==============================] - 33s 53ms/step - loss: 0.0320 - accuracy: 0.9892 - val_loss: 0.5304 - val_accuracy: 0.8531\n",
            "Epoch 6/10\n",
            "620/620 [==============================] - 32s 52ms/step - loss: 0.0279 - accuracy: 0.9901 - val_loss: 0.5564 - val_accuracy: 0.8713\n",
            "Epoch 7/10\n",
            "620/620 [==============================] - 35s 57ms/step - loss: 0.0239 - accuracy: 0.9915 - val_loss: 0.5636 - val_accuracy: 0.8882\n",
            "Epoch 8/10\n",
            "620/620 [==============================] - 35s 57ms/step - loss: 0.0219 - accuracy: 0.9916 - val_loss: 0.6423 - val_accuracy: 0.8705\n",
            "Epoch 9/10\n",
            "620/620 [==============================] - 33s 53ms/step - loss: 0.0580 - accuracy: 0.9789 - val_loss: 0.6673 - val_accuracy: 0.8588\n",
            "Epoch 10/10\n",
            "620/620 [==============================] - 32s 52ms/step - loss: 0.0204 - accuracy: 0.9926 - val_loss: 0.6930 - val_accuracy: 0.8667\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f59a343cd90>"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_embeddings = model.layers[0].get_weights()[0]\n",
        "rnn_embeddings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXmMTCyATcgm",
        "outputId": "47280b07-3a44-4650-ebad-89382d3ae2a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.01581835,  0.02156218, -0.06654426, ..., -0.01921615,\n",
              "         0.00106114, -0.0058489 ],\n",
              "       [-0.01933762, -0.00727147,  0.169275  , ...,  0.11585952,\n",
              "        -0.22337076,  0.14639181],\n",
              "       [ 0.03624801,  0.02861097, -0.00672321, ..., -0.00611927,\n",
              "         0.02496484, -0.04060837],\n",
              "       ...,\n",
              "       [-0.03060452,  0.00888643,  0.03988672, ..., -0.04953717,\n",
              "         0.04128316,  0.02194059],\n",
              "       [-0.01201225, -0.04464687,  0.02023626, ...,  0.01762203,\n",
              "        -0.02263118,  0.01549162],\n",
              "       [ 0.01737351, -0.00876598, -0.00832968, ...,  0.01395141,\n",
              "        -0.04519268,  0.04634757]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 5**"
      ],
      "metadata": {
        "id": "NZJvRnxZWN7n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Application: Hate Speech Identification\n",
        "Dataset: Download the dataset from Annotated Corpus for Named Entity Recognition (kaggle.com)\n",
        "Task:\n",
        "• Develop a model for Named Entity Recognition using Hidden Markov Model.\n",
        "• Remove the labels from the Corpus and use Baum Welch algorithm to estimate the learning\n",
        "parameters."
      ],
      "metadata": {
        "id": "TZhLM_xHWQi_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "8K4YXCdtWXhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exercise 6**"
      ],
      "metadata": {
        "id": "tvBz-JUSYkqw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Application: Keyword Extraction\n",
        "Dataset: Download the dataset from SemEval2017\n",
        "Task:\n",
        "• Develop a model for identifying and extracting keywords/ key phrases from the input sequence.\n",
        "• Use Named Entity Recognition and PoS tagging as a feature that contribute to the extraction."
      ],
      "metadata": {
        "id": "AOOix5vjYnU_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DVABottbs5zg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exercise 8**"
      ],
      "metadata": {
        "id": "LR8ukQJqZ6M0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Application: Machine Translation\n",
        "\n",
        "Dataset: Download the dataset from\n",
        "Tamil-English-Dataset/Dataset at master · Ishikahooda/Tamil-English-Dataset · GitHub\n",
        "English_to_tamil_data (kaggle.com)\n",
        "\n",
        "Task:\n",
        "• Develop a model that can translate a Tamil input sentence to English.\n",
        "• Analyze the impact of various embedding techniques in the translation task.\n",
        "• Use sequence model to translate the Tamil input sentence and analyze the performance of\n",
        "various techniques.\n",
        "• Translate the input sentences using Transformer model and understand its functioning.\n",
        "• Translate the following Tamil Phrase and evaluate your model based on the expected output.\n",
        "\n",
        "\n",
        "Input 1: நான் மிகவும் சந்த ாஷமாக இருக்கிதேன்\n",
        "Expected Output: Im so happy\n",
        "Input 2: அது அவசியமில்லை\n",
        "Expected Output: It wasnt necessary\n",
        "Input 3: யவுசசய்து அல மீண்டும் சசய்யவும்\n",
        "Expected Output: Please do that again\n",
        "Input 4: அது ஒரு நல்ை தயாசலை\n",
        "Expected Output: That is a good idea\n",
        "Input 5: அவர்கள் ஒன்ோக தவலை சசய்ய ஒப்புக்சகாண்டைர்\n",
        "Expected Output: They agreed to work together"
      ],
      "metadata": {
        "id": "Qkrx63m7Z8oB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://alvinntnu.github.io/python-notes/nlp/seq-to-seq-machine-translation.html"
      ],
      "metadata": {
        "id": "b83trNs_mD1x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.tensorflow.org/text/tutorials/transformer"
      ],
      "metadata": {
        "id": "rrG2PVKMulcG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/tam.txt\", encoding=\"utf8\") as f:\n",
        "    data = f.read().split(\"\\n\")\n",
        "\n",
        "X_txt = []\n",
        "y_txt = []\n",
        "\n",
        "X_voc = set()\n",
        "y_voc = set()\n",
        "\n",
        "for line in data:\n",
        "    # Skip In-Valid Seq\n",
        "    if(len(line.split(\"\\t\")) != 3):\n",
        "        continue\n",
        "\n",
        "    target, inp, _ = line.split(\"\\t\")\n",
        "    target = \"\\t\" + target + \"\\n\" # \"\\t\" -> Start Seq, \"\\n\" -> End Seq\n",
        "\n",
        "    X_txt.append(inp)\n",
        "    y_txt.append(target)\n",
        "\n",
        "    X_voc.update(set(inp))\n",
        "    y_voc.update(set(target))"
      ],
      "metadata": {
        "id": "rervY5rJulOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"No of Records : \", len(X_txt), end=\"\\n\\n\")\n",
        "\n",
        "X_voc = sorted(list(X_voc))\n",
        "y_voc = sorted(list(y_voc))\n",
        "\n",
        "print(\"Vocab Size of Input tok : \", len(X_voc))\n",
        "print(\"vocab Size of Output tok : \", len(y_voc), end=\"\\n\\n\")\n",
        "\n",
        "max_encoder = max([len(t) for t in X_txt])\n",
        "max_decoder = max([len(t) for t in y_txt])\n",
        "\n",
        "print(\"Max Seq length for input : \", max_encoder)\n",
        "print(\"Max Seq length for output : \", max_decoder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-1A27uTujJ3",
        "outputId": "381fa046-31c5-444c-feb7-2fa490b6ead9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No of Records :  201\n",
            "\n",
            "Vocab Size of Input tok :  52\n",
            "vocab Size of Output tok :  55\n",
            "\n",
            "Max Seq length for input :  109\n",
            "Max Seq length for output :  96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenisation\n",
        "\n",
        "input_tok_enc = dict([(char, i) for i, char in enumerate(X_voc)])\n",
        "input_tok_dec = dict([(i, char) for i, char in enumerate(X_voc)])\n",
        "\n",
        "target_tok_enc = dict([(char, i) for i, char in enumerate(y_voc)])\n",
        "target_tok_dec = dict([(i, char) for i, char in enumerate(y_voc)])\n",
        "X = [[input_tok_enc[char] for char in text] for text in X_txt]\n",
        "y = [[target_tok_enc[char] for char in text] for text in y_txt]"
      ],
      "metadata": {
        "id": "xA1xRS7JujHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Padding\n",
        "\n",
        "from tensorflow.keras.utils import pad_sequences\n",
        "\n",
        "X = pad_sequences(X, maxlen=max_encoder, padding=\"post\", value=input_tok_enc[' '])\n",
        "y = pad_sequences(y, maxlen=max_decoder, padding=\"post\", value=target_tok_enc[' '])"
      ],
      "metadata": {
        "id": "dCNAJtHAujD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, LSTM, CategoryEncoding\n",
        "\n",
        "latent_dim = 256\n",
        "\n",
        "# Encoder Block\n",
        "encoder_inputs = Input(shape=(None, len(X_voc)))\n",
        "encoder = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Decoder Block\n",
        "decoder_inputs = (Input(shape=(None, len(y_voc))))\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "decoder_dense = Dense(len(y_voc), activation=\"softmax\")\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "import tensorflow as tf\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lR9B83-YujBW",
        "outputId": "685cc478-09e7-4cba-fa95-3e5ad4630ed2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_10\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_13 (InputLayer)       [(None, None, 52)]           0         []                            \n",
            "                                                                                                  \n",
            " input_14 (InputLayer)       [(None, None, 55)]           0         []                            \n",
            "                                                                                                  \n",
            " lstm_8 (LSTM)               [(None, 256),                316416    ['input_13[0][0]']            \n",
            "                              (None, 256),                                                        \n",
            "                              (None, 256)]                                                        \n",
            "                                                                                                  \n",
            " lstm_9 (LSTM)               [(None, None, 256),          319488    ['input_14[0][0]',            \n",
            "                              (None, 256),                           'lstm_8[0][1]',              \n",
            "                              (None, 256)]                           'lstm_8[0][2]']              \n",
            "                                                                                                  \n",
            " dense_4 (Dense)             (None, None, 55)             14135     ['lstm_9[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 650039 (2.48 MB)\n",
            "Trainable params: 650039 (2.48 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "encoder_input_data = np.zeros((len(X), max_encoder, len(X_voc)), dtype=\"float\")\n",
        "for i, line in enumerate(X):\n",
        "    for j, k in enumerate(line):\n",
        "        encoder_input_data[i][j][k] = 1.0\n",
        "\n",
        "decoder_input_data = np.zeros((len(X), max_decoder, len(y_voc)), dtype=\"float\")\n",
        "decoder_target_data = np.zeros((len(X), max_decoder, len(y_voc)), dtype=\"float\")\n",
        "for i, line in enumerate(y):\n",
        "    for j, k in enumerate(line):\n",
        "        decoder_input_data[i, j, k] = 1.0\n",
        "        if(j > 0):\n",
        "            decoder_target_data[i, j-1, k] = 1.0\n",
        "\n",
        "model.fit([encoder_input_data, decoder_input_data], decoder_target_data, batch_size=64, epochs=500, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m34Ym6JAu-5u",
        "outputId": "ea898dbe-31be-4e14-ecec-e1f718cd2956"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.4889 - accuracy: 0.8553 - val_loss: 1.4174 - val_accuracy: 0.6664\n",
            "Epoch 2/500\n",
            "3/3 [==============================] - 3s 1s/step - loss: 0.4858 - accuracy: 0.8579 - val_loss: 1.3808 - val_accuracy: 0.6723\n",
            "Epoch 3/500\n",
            "3/3 [==============================] - 3s 867ms/step - loss: 0.4841 - accuracy: 0.8571 - val_loss: 1.3818 - val_accuracy: 0.6669\n",
            "Epoch 4/500\n",
            "3/3 [==============================] - 3s 924ms/step - loss: 0.4864 - accuracy: 0.8561 - val_loss: 1.3403 - val_accuracy: 0.6662\n",
            "Epoch 5/500\n",
            "3/3 [==============================] - 2s 593ms/step - loss: 0.4846 - accuracy: 0.8574 - val_loss: 1.3713 - val_accuracy: 0.6695\n",
            "Epoch 6/500\n",
            "3/3 [==============================] - 2s 599ms/step - loss: 0.4877 - accuracy: 0.8585 - val_loss: 1.4119 - val_accuracy: 0.6659\n",
            "Epoch 7/500\n",
            "3/3 [==============================] - 2s 598ms/step - loss: 0.4948 - accuracy: 0.8568 - val_loss: 1.3253 - val_accuracy: 0.6715\n",
            "Epoch 8/500\n",
            "3/3 [==============================] - 2s 595ms/step - loss: 0.4859 - accuracy: 0.8570 - val_loss: 1.3659 - val_accuracy: 0.6720\n",
            "Epoch 9/500\n",
            "3/3 [==============================] - 2s 604ms/step - loss: 0.4790 - accuracy: 0.8586 - val_loss: 1.3766 - val_accuracy: 0.6735\n",
            "Epoch 10/500\n",
            "3/3 [==============================] - 2s 867ms/step - loss: 0.4754 - accuracy: 0.8586 - val_loss: 1.3624 - val_accuracy: 0.6700\n",
            "Epoch 11/500\n",
            "3/3 [==============================] - 2s 656ms/step - loss: 0.4757 - accuracy: 0.8578 - val_loss: 1.4148 - val_accuracy: 0.6707\n",
            "Epoch 12/500\n",
            "3/3 [==============================] - 2s 595ms/step - loss: 0.4747 - accuracy: 0.8583 - val_loss: 1.3971 - val_accuracy: 0.6735\n",
            "Epoch 13/500\n",
            "3/3 [==============================] - 2s 598ms/step - loss: 0.4779 - accuracy: 0.8584 - val_loss: 1.3367 - val_accuracy: 0.6692\n",
            "Epoch 14/500\n",
            "3/3 [==============================] - 2s 613ms/step - loss: 0.4857 - accuracy: 0.8581 - val_loss: 1.3334 - val_accuracy: 0.6771\n",
            "Epoch 15/500\n",
            "3/3 [==============================] - 2s 599ms/step - loss: 0.4819 - accuracy: 0.8576 - val_loss: 1.3619 - val_accuracy: 0.6667\n",
            "Epoch 16/500\n",
            "3/3 [==============================] - 2s 695ms/step - loss: 0.4757 - accuracy: 0.8607 - val_loss: 1.3430 - val_accuracy: 0.6789\n",
            "Epoch 17/500\n",
            "3/3 [==============================] - 2s 628ms/step - loss: 0.4695 - accuracy: 0.8605 - val_loss: 1.4777 - val_accuracy: 0.6672\n",
            "Epoch 18/500\n",
            "3/3 [==============================] - 2s 602ms/step - loss: 0.4698 - accuracy: 0.8598 - val_loss: 1.3359 - val_accuracy: 0.6771\n",
            "Epoch 19/500\n",
            "3/3 [==============================] - 2s 598ms/step - loss: 0.4686 - accuracy: 0.8598 - val_loss: 1.3238 - val_accuracy: 0.6728\n",
            "Epoch 20/500\n",
            "3/3 [==============================] - 2s 606ms/step - loss: 0.4672 - accuracy: 0.8607 - val_loss: 1.3835 - val_accuracy: 0.6697\n",
            "Epoch 21/500\n",
            "3/3 [==============================] - 2s 611ms/step - loss: 0.4658 - accuracy: 0.8604 - val_loss: 1.3298 - val_accuracy: 0.6771\n",
            "Epoch 22/500\n",
            "3/3 [==============================] - 2s 675ms/step - loss: 0.4681 - accuracy: 0.8620 - val_loss: 1.3391 - val_accuracy: 0.6725\n",
            "Epoch 23/500\n",
            "3/3 [==============================] - 2s 637ms/step - loss: 0.4665 - accuracy: 0.8633 - val_loss: 1.3291 - val_accuracy: 0.6784\n",
            "Epoch 24/500\n",
            "3/3 [==============================] - 2s 591ms/step - loss: 0.4661 - accuracy: 0.8616 - val_loss: 1.3504 - val_accuracy: 0.6743\n",
            "Epoch 25/500\n",
            "3/3 [==============================] - 2s 603ms/step - loss: 0.4629 - accuracy: 0.8606 - val_loss: 1.3374 - val_accuracy: 0.6723\n",
            "Epoch 26/500\n",
            "3/3 [==============================] - 2s 602ms/step - loss: 0.4639 - accuracy: 0.8621 - val_loss: 1.3162 - val_accuracy: 0.6753\n",
            "Epoch 27/500\n",
            "3/3 [==============================] - 2s 596ms/step - loss: 0.4615 - accuracy: 0.8633 - val_loss: 1.3743 - val_accuracy: 0.6753\n",
            "Epoch 28/500\n",
            "3/3 [==============================] - 2s 610ms/step - loss: 0.4586 - accuracy: 0.8638 - val_loss: 1.2617 - val_accuracy: 0.6789\n",
            "Epoch 29/500\n",
            "3/3 [==============================] - 2s 662ms/step - loss: 0.4612 - accuracy: 0.8626 - val_loss: 1.3731 - val_accuracy: 0.6684\n",
            "Epoch 30/500\n",
            "3/3 [==============================] - 2s 611ms/step - loss: 0.4657 - accuracy: 0.8615 - val_loss: 1.3068 - val_accuracy: 0.6712\n",
            "Epoch 31/500\n",
            "3/3 [==============================] - 2s 596ms/step - loss: 0.4623 - accuracy: 0.8628 - val_loss: 1.3271 - val_accuracy: 0.6768\n",
            "Epoch 32/500\n",
            "3/3 [==============================] - 2s 601ms/step - loss: 0.4649 - accuracy: 0.8629 - val_loss: 1.2203 - val_accuracy: 0.6837\n",
            "Epoch 33/500\n",
            "3/3 [==============================] - 2s 597ms/step - loss: 0.4622 - accuracy: 0.8612 - val_loss: 1.3293 - val_accuracy: 0.6761\n",
            "Epoch 34/500\n",
            "3/3 [==============================] - 2s 590ms/step - loss: 0.4593 - accuracy: 0.8615 - val_loss: 1.3558 - val_accuracy: 0.6832\n",
            "Epoch 35/500\n",
            "3/3 [==============================] - 2s 727ms/step - loss: 0.4550 - accuracy: 0.8620 - val_loss: 1.3285 - val_accuracy: 0.6789\n",
            "Epoch 36/500\n",
            "3/3 [==============================] - 2s 601ms/step - loss: 0.4538 - accuracy: 0.8656 - val_loss: 1.3208 - val_accuracy: 0.6817\n",
            "Epoch 37/500\n",
            "3/3 [==============================] - 2s 607ms/step - loss: 0.4533 - accuracy: 0.8626 - val_loss: 1.3354 - val_accuracy: 0.6776\n",
            "Epoch 38/500\n",
            "3/3 [==============================] - 2s 606ms/step - loss: 0.4506 - accuracy: 0.8647 - val_loss: 1.3372 - val_accuracy: 0.6822\n",
            "Epoch 39/500\n",
            "3/3 [==============================] - 2s 590ms/step - loss: 0.4533 - accuracy: 0.8658 - val_loss: 1.4173 - val_accuracy: 0.6771\n",
            "Epoch 40/500\n",
            "3/3 [==============================] - 2s 602ms/step - loss: 0.4497 - accuracy: 0.8630 - val_loss: 1.4114 - val_accuracy: 0.6756\n",
            "Epoch 41/500\n",
            "3/3 [==============================] - 2s 753ms/step - loss: 0.4604 - accuracy: 0.8645 - val_loss: 1.4195 - val_accuracy: 0.6745\n",
            "Epoch 42/500\n",
            "3/3 [==============================] - 2s 701ms/step - loss: 0.4512 - accuracy: 0.8661 - val_loss: 1.4671 - val_accuracy: 0.6806\n",
            "Epoch 43/500\n",
            "3/3 [==============================] - 2s 596ms/step - loss: 0.4462 - accuracy: 0.8639 - val_loss: 1.3586 - val_accuracy: 0.6751\n",
            "Epoch 44/500\n",
            "3/3 [==============================] - 2s 581ms/step - loss: 0.4528 - accuracy: 0.8667 - val_loss: 1.3773 - val_accuracy: 0.6776\n",
            "Epoch 45/500\n",
            "3/3 [==============================] - 2s 587ms/step - loss: 0.4525 - accuracy: 0.8622 - val_loss: 1.3602 - val_accuracy: 0.6743\n",
            "Epoch 46/500\n",
            "3/3 [==============================] - 2s 608ms/step - loss: 0.4486 - accuracy: 0.8662 - val_loss: 1.2961 - val_accuracy: 0.6829\n",
            "Epoch 47/500\n",
            "3/3 [==============================] - 2s 743ms/step - loss: 0.4453 - accuracy: 0.8663 - val_loss: 1.3616 - val_accuracy: 0.6756\n",
            "Epoch 48/500\n",
            "3/3 [==============================] - 2s 610ms/step - loss: 0.4437 - accuracy: 0.8649 - val_loss: 1.3580 - val_accuracy: 0.6817\n",
            "Epoch 49/500\n",
            "3/3 [==============================] - 2s 592ms/step - loss: 0.4444 - accuracy: 0.8657 - val_loss: 1.3551 - val_accuracy: 0.6773\n",
            "Epoch 50/500\n",
            "3/3 [==============================] - 2s 600ms/step - loss: 0.4424 - accuracy: 0.8668 - val_loss: 1.3600 - val_accuracy: 0.6817\n",
            "Epoch 51/500\n",
            "3/3 [==============================] - 2s 612ms/step - loss: 0.4401 - accuracy: 0.8656 - val_loss: 1.3403 - val_accuracy: 0.6819\n",
            "Epoch 52/500\n",
            "3/3 [==============================] - 2s 602ms/step - loss: 0.4375 - accuracy: 0.8683 - val_loss: 1.3003 - val_accuracy: 0.6834\n",
            "Epoch 53/500\n",
            "3/3 [==============================] - 2s 778ms/step - loss: 0.4380 - accuracy: 0.8673 - val_loss: 1.3492 - val_accuracy: 0.6832\n",
            "Epoch 54/500\n",
            "3/3 [==============================] - 2s 594ms/step - loss: 0.4375 - accuracy: 0.8677 - val_loss: 1.3567 - val_accuracy: 0.6855\n",
            "Epoch 55/500\n",
            "3/3 [==============================] - 2s 595ms/step - loss: 0.4354 - accuracy: 0.8682 - val_loss: 1.3606 - val_accuracy: 0.6799\n",
            "Epoch 56/500\n",
            "3/3 [==============================] - 2s 608ms/step - loss: 0.4335 - accuracy: 0.8680 - val_loss: 1.3303 - val_accuracy: 0.6839\n",
            "Epoch 57/500\n",
            "3/3 [==============================] - 2s 598ms/step - loss: 0.4339 - accuracy: 0.8682 - val_loss: 1.3811 - val_accuracy: 0.6822\n",
            "Epoch 58/500\n",
            "3/3 [==============================] - 2s 598ms/step - loss: 0.4338 - accuracy: 0.8680 - val_loss: 1.4044 - val_accuracy: 0.6801\n",
            "Epoch 59/500\n",
            "3/3 [==============================] - 2s 808ms/step - loss: 0.4317 - accuracy: 0.8680 - val_loss: 1.3522 - val_accuracy: 0.6817\n",
            "Epoch 60/500\n",
            "3/3 [==============================] - 2s 604ms/step - loss: 0.4357 - accuracy: 0.8695 - val_loss: 1.4351 - val_accuracy: 0.6791\n",
            "Epoch 61/500\n",
            "3/3 [==============================] - 2s 745ms/step - loss: 0.4321 - accuracy: 0.8682 - val_loss: 1.3408 - val_accuracy: 0.6857\n",
            "Epoch 62/500\n",
            "3/3 [==============================] - 2s 608ms/step - loss: 0.4313 - accuracy: 0.8702 - val_loss: 1.4414 - val_accuracy: 0.6723\n",
            "Epoch 63/500\n",
            "3/3 [==============================] - 2s 589ms/step - loss: 0.4297 - accuracy: 0.8691 - val_loss: 1.3704 - val_accuracy: 0.6908\n",
            "Epoch 64/500\n",
            "3/3 [==============================] - 2s 612ms/step - loss: 0.4281 - accuracy: 0.8689 - val_loss: 1.3456 - val_accuracy: 0.6804\n",
            "Epoch 65/500\n",
            "3/3 [==============================] - 2s 723ms/step - loss: 0.4593 - accuracy: 0.8708 - val_loss: 1.3453 - val_accuracy: 0.6817\n",
            "Epoch 66/500\n",
            "3/3 [==============================] - 2s 616ms/step - loss: 0.4469 - accuracy: 0.8680 - val_loss: 1.3374 - val_accuracy: 0.6845\n",
            "Epoch 67/500\n",
            "3/3 [==============================] - 2s 614ms/step - loss: 0.4346 - accuracy: 0.8677 - val_loss: 1.3880 - val_accuracy: 0.6819\n",
            "Epoch 68/500\n",
            "3/3 [==============================] - 2s 597ms/step - loss: 0.4261 - accuracy: 0.8706 - val_loss: 1.3171 - val_accuracy: 0.6814\n",
            "Epoch 69/500\n",
            "3/3 [==============================] - 2s 588ms/step - loss: 0.4251 - accuracy: 0.8707 - val_loss: 1.4206 - val_accuracy: 0.6834\n",
            "Epoch 70/500\n",
            "3/3 [==============================] - 2s 614ms/step - loss: 0.4211 - accuracy: 0.8696 - val_loss: 1.4450 - val_accuracy: 0.6809\n",
            "Epoch 71/500\n",
            "3/3 [==============================] - 2s 746ms/step - loss: 0.4215 - accuracy: 0.8701 - val_loss: 1.4107 - val_accuracy: 0.6845\n",
            "Epoch 72/500\n",
            "3/3 [==============================] - 2s 602ms/step - loss: 0.4221 - accuracy: 0.8703 - val_loss: 1.4826 - val_accuracy: 0.6811\n",
            "Epoch 73/500\n",
            "3/3 [==============================] - 2s 600ms/step - loss: 0.4214 - accuracy: 0.8692 - val_loss: 1.3450 - val_accuracy: 0.6822\n",
            "Epoch 74/500\n",
            "3/3 [==============================] - 2s 594ms/step - loss: 0.4196 - accuracy: 0.8715 - val_loss: 1.3710 - val_accuracy: 0.6847\n",
            "Epoch 75/500\n",
            "3/3 [==============================] - 2s 600ms/step - loss: 0.4204 - accuracy: 0.8704 - val_loss: 1.3773 - val_accuracy: 0.6819\n",
            "Epoch 76/500\n",
            "3/3 [==============================] - 2s 598ms/step - loss: 0.4200 - accuracy: 0.8725 - val_loss: 1.3954 - val_accuracy: 0.6794\n",
            "Epoch 77/500\n",
            "3/3 [==============================] - 2s 803ms/step - loss: 0.4195 - accuracy: 0.8720 - val_loss: 1.3524 - val_accuracy: 0.6872\n",
            "Epoch 78/500\n",
            "3/3 [==============================] - 2s 610ms/step - loss: 0.4186 - accuracy: 0.8730 - val_loss: 1.3738 - val_accuracy: 0.6817\n",
            "Epoch 79/500\n",
            "3/3 [==============================] - 2s 608ms/step - loss: 0.4173 - accuracy: 0.8721 - val_loss: 1.3133 - val_accuracy: 0.6855\n",
            "Epoch 80/500\n",
            "3/3 [==============================] - 2s 731ms/step - loss: 0.4179 - accuracy: 0.8706 - val_loss: 1.3794 - val_accuracy: 0.6855\n",
            "Epoch 81/500\n",
            "3/3 [==============================] - 2s 606ms/step - loss: 0.4143 - accuracy: 0.8725 - val_loss: 1.3567 - val_accuracy: 0.6819\n",
            "Epoch 82/500\n",
            "3/3 [==============================] - 2s 594ms/step - loss: 0.4132 - accuracy: 0.8715 - val_loss: 1.3145 - val_accuracy: 0.6847\n",
            "Epoch 83/500\n",
            "3/3 [==============================] - 2s 741ms/step - loss: 0.4109 - accuracy: 0.8721 - val_loss: 1.3666 - val_accuracy: 0.6870\n",
            "Epoch 84/500\n",
            "3/3 [==============================] - 2s 604ms/step - loss: 0.4112 - accuracy: 0.8723 - val_loss: 1.4321 - val_accuracy: 0.6817\n",
            "Epoch 85/500\n",
            "3/3 [==============================] - 2s 608ms/step - loss: 0.4406 - accuracy: 0.8712 - val_loss: 1.4718 - val_accuracy: 0.6791\n",
            "Epoch 86/500\n",
            "3/3 [==============================] - 2s 605ms/step - loss: 0.4292 - accuracy: 0.8710 - val_loss: 1.3677 - val_accuracy: 0.6842\n",
            "Epoch 87/500\n",
            "3/3 [==============================] - 2s 596ms/step - loss: 0.4147 - accuracy: 0.8721 - val_loss: 1.4044 - val_accuracy: 0.6852\n",
            "Epoch 88/500\n",
            "3/3 [==============================] - 2s 605ms/step - loss: 0.4110 - accuracy: 0.8725 - val_loss: 1.3975 - val_accuracy: 0.6872\n",
            "Epoch 89/500\n",
            "3/3 [==============================] - 2s 809ms/step - loss: 0.4121 - accuracy: 0.8721 - val_loss: 1.3963 - val_accuracy: 0.6796\n",
            "Epoch 90/500\n",
            "3/3 [==============================] - 2s 594ms/step - loss: 0.4101 - accuracy: 0.8719 - val_loss: 1.4156 - val_accuracy: 0.6829\n",
            "Epoch 91/500\n",
            "3/3 [==============================] - 2s 605ms/step - loss: 0.4116 - accuracy: 0.8726 - val_loss: 1.3317 - val_accuracy: 0.6870\n",
            "Epoch 92/500\n",
            "3/3 [==============================] - 2s 598ms/step - loss: 0.4118 - accuracy: 0.8727 - val_loss: 1.3862 - val_accuracy: 0.6791\n",
            "Epoch 93/500\n",
            "3/3 [==============================] - 2s 599ms/step - loss: 0.4095 - accuracy: 0.8730 - val_loss: 1.4476 - val_accuracy: 0.6824\n",
            "Epoch 94/500\n",
            "3/3 [==============================] - 2s 603ms/step - loss: 0.4073 - accuracy: 0.8727 - val_loss: 1.4133 - val_accuracy: 0.6872\n",
            "Epoch 95/500\n",
            "3/3 [==============================] - 2s 813ms/step - loss: 0.4081 - accuracy: 0.8740 - val_loss: 1.4439 - val_accuracy: 0.6768\n",
            "Epoch 96/500\n",
            "3/3 [==============================] - 2s 607ms/step - loss: 0.4072 - accuracy: 0.8725 - val_loss: 1.3638 - val_accuracy: 0.6926\n",
            "Epoch 97/500\n",
            "3/3 [==============================] - 2s 589ms/step - loss: 0.4053 - accuracy: 0.8731 - val_loss: 1.3904 - val_accuracy: 0.6839\n",
            "Epoch 98/500\n",
            "3/3 [==============================] - 2s 603ms/step - loss: 0.4031 - accuracy: 0.8748 - val_loss: 1.3235 - val_accuracy: 0.6878\n",
            "Epoch 99/500\n",
            "3/3 [==============================] - 2s 588ms/step - loss: 0.4090 - accuracy: 0.8755 - val_loss: 1.4733 - val_accuracy: 0.6832\n",
            "Epoch 100/500\n",
            "3/3 [==============================] - 2s 593ms/step - loss: 0.4069 - accuracy: 0.8748 - val_loss: 1.3378 - val_accuracy: 0.6855\n",
            "Epoch 101/500\n",
            "3/3 [==============================] - 2s 822ms/step - loss: 0.4319 - accuracy: 0.8758 - val_loss: 1.4420 - val_accuracy: 0.6768\n",
            "Epoch 102/500\n",
            "3/3 [==============================] - 2s 599ms/step - loss: 0.4214 - accuracy: 0.8725 - val_loss: 1.2898 - val_accuracy: 0.6872\n",
            "Epoch 103/500\n",
            "3/3 [==============================] - 2s 600ms/step - loss: 0.4100 - accuracy: 0.8754 - val_loss: 1.3571 - val_accuracy: 0.6799\n",
            "Epoch 104/500\n",
            "3/3 [==============================] - 2s 591ms/step - loss: 0.4031 - accuracy: 0.8750 - val_loss: 1.3515 - val_accuracy: 0.6829\n",
            "Epoch 105/500\n",
            "3/3 [==============================] - 2s 603ms/step - loss: 0.3996 - accuracy: 0.8745 - val_loss: 1.3428 - val_accuracy: 0.6862\n",
            "Epoch 106/500\n",
            "3/3 [==============================] - 2s 592ms/step - loss: 0.3972 - accuracy: 0.8750 - val_loss: 1.3509 - val_accuracy: 0.6822\n",
            "Epoch 107/500\n",
            "3/3 [==============================] - 2s 860ms/step - loss: 0.3950 - accuracy: 0.8760 - val_loss: 1.3530 - val_accuracy: 0.6842\n",
            "Epoch 108/500\n",
            "3/3 [==============================] - 2s 594ms/step - loss: 0.3945 - accuracy: 0.8755 - val_loss: 1.3181 - val_accuracy: 0.6829\n",
            "Epoch 109/500\n",
            "3/3 [==============================] - 2s 599ms/step - loss: 0.3958 - accuracy: 0.8751 - val_loss: 1.3780 - val_accuracy: 0.6763\n",
            "Epoch 110/500\n",
            "3/3 [==============================] - 2s 593ms/step - loss: 0.3967 - accuracy: 0.8756 - val_loss: 1.3936 - val_accuracy: 0.6778\n",
            "Epoch 111/500\n",
            "3/3 [==============================] - 2s 605ms/step - loss: 0.3962 - accuracy: 0.8760 - val_loss: 1.3290 - val_accuracy: 0.6845\n",
            "Epoch 112/500\n",
            "3/3 [==============================] - 2s 601ms/step - loss: 0.3973 - accuracy: 0.8770 - val_loss: 1.3670 - val_accuracy: 0.6791\n",
            "Epoch 113/500\n",
            "3/3 [==============================] - 2s 832ms/step - loss: 0.3967 - accuracy: 0.8755 - val_loss: 1.3100 - val_accuracy: 0.6827\n",
            "Epoch 114/500\n",
            "3/3 [==============================] - 2s 598ms/step - loss: 0.3966 - accuracy: 0.8761 - val_loss: 1.2870 - val_accuracy: 0.6839\n",
            "Epoch 115/500\n",
            "3/3 [==============================] - 2s 605ms/step - loss: 0.3955 - accuracy: 0.8770 - val_loss: 1.3362 - val_accuracy: 0.6811\n",
            "Epoch 116/500\n",
            "3/3 [==============================] - 2s 596ms/step - loss: 0.3912 - accuracy: 0.8768 - val_loss: 1.3194 - val_accuracy: 0.6814\n",
            "Epoch 117/500\n",
            "3/3 [==============================] - 2s 601ms/step - loss: 0.3903 - accuracy: 0.8768 - val_loss: 1.3589 - val_accuracy: 0.6811\n",
            "Epoch 118/500\n",
            "3/3 [==============================] - 2s 600ms/step - loss: 0.3884 - accuracy: 0.8777 - val_loss: 1.3246 - val_accuracy: 0.6862\n",
            "Epoch 119/500\n",
            "3/3 [==============================] - 2s 763ms/step - loss: 0.3874 - accuracy: 0.8781 - val_loss: 1.3933 - val_accuracy: 0.6768\n",
            "Epoch 120/500\n",
            "3/3 [==============================] - 2s 605ms/step - loss: 0.3876 - accuracy: 0.8770 - val_loss: 1.3438 - val_accuracy: 0.6824\n",
            "Epoch 121/500\n",
            "3/3 [==============================] - 2s 588ms/step - loss: 0.3878 - accuracy: 0.8779 - val_loss: 1.3499 - val_accuracy: 0.6824\n",
            "Epoch 122/500\n",
            "3/3 [==============================] - 2s 601ms/step - loss: 0.3861 - accuracy: 0.8788 - val_loss: 1.3671 - val_accuracy: 0.6824\n",
            "Epoch 123/500\n",
            "3/3 [==============================] - 2s 602ms/step - loss: 0.3844 - accuracy: 0.8778 - val_loss: 1.3634 - val_accuracy: 0.6827\n",
            "Epoch 124/500\n",
            "3/3 [==============================] - 2s 603ms/step - loss: 0.3851 - accuracy: 0.8786 - val_loss: 1.3741 - val_accuracy: 0.6789\n",
            "Epoch 125/500\n",
            "3/3 [==============================] - 2s 728ms/step - loss: 0.3840 - accuracy: 0.8783 - val_loss: 1.2892 - val_accuracy: 0.6857\n",
            "Epoch 126/500\n",
            "3/3 [==============================] - 2s 589ms/step - loss: 0.3843 - accuracy: 0.8806 - val_loss: 1.3656 - val_accuracy: 0.6781\n",
            "Epoch 127/500\n",
            "3/3 [==============================] - 2s 597ms/step - loss: 0.3850 - accuracy: 0.8789 - val_loss: 1.3302 - val_accuracy: 0.6865\n",
            "Epoch 128/500\n",
            "3/3 [==============================] - 2s 603ms/step - loss: 0.3842 - accuracy: 0.8783 - val_loss: 1.3334 - val_accuracy: 0.6850\n",
            "Epoch 129/500\n",
            "3/3 [==============================] - 2s 603ms/step - loss: 0.3826 - accuracy: 0.8800 - val_loss: 1.3757 - val_accuracy: 0.6796\n",
            "Epoch 130/500\n",
            "3/3 [==============================] - 2s 596ms/step - loss: 0.3796 - accuracy: 0.8793 - val_loss: 1.2947 - val_accuracy: 0.6883\n",
            "Epoch 131/500\n",
            "3/3 [==============================] - 2s 681ms/step - loss: 0.3802 - accuracy: 0.8813 - val_loss: 1.3515 - val_accuracy: 0.6832\n",
            "Epoch 132/500\n",
            "3/3 [==============================] - 2s 622ms/step - loss: 0.3795 - accuracy: 0.8792 - val_loss: 1.3054 - val_accuracy: 0.6867\n",
            "Epoch 133/500\n",
            "3/3 [==============================] - 2s 609ms/step - loss: 0.3789 - accuracy: 0.8818 - val_loss: 1.3370 - val_accuracy: 0.6845\n",
            "Epoch 134/500\n",
            "3/3 [==============================] - 2s 599ms/step - loss: 0.3779 - accuracy: 0.8807 - val_loss: 1.3580 - val_accuracy: 0.6819\n",
            "Epoch 135/500\n",
            "3/3 [==============================] - 2s 609ms/step - loss: 0.3755 - accuracy: 0.8822 - val_loss: 1.3536 - val_accuracy: 0.6867\n",
            "Epoch 136/500\n",
            "3/3 [==============================] - 2s 606ms/step - loss: 0.3755 - accuracy: 0.8811 - val_loss: 1.3649 - val_accuracy: 0.6809\n",
            "Epoch 137/500\n",
            "3/3 [==============================] - 2s 636ms/step - loss: 0.3755 - accuracy: 0.8820 - val_loss: 1.3447 - val_accuracy: 0.6829\n",
            "Epoch 138/500\n",
            "3/3 [==============================] - 2s 641ms/step - loss: 0.3752 - accuracy: 0.8816 - val_loss: 1.3736 - val_accuracy: 0.6850\n",
            "Epoch 139/500\n",
            "3/3 [==============================] - 2s 601ms/step - loss: 0.3747 - accuracy: 0.8815 - val_loss: 1.3645 - val_accuracy: 0.6824\n",
            "Epoch 140/500\n",
            "3/3 [==============================] - 2s 597ms/step - loss: 0.3741 - accuracy: 0.8829 - val_loss: 1.3871 - val_accuracy: 0.6804\n",
            "Epoch 141/500\n",
            "3/3 [==============================] - 2s 616ms/step - loss: 0.3756 - accuracy: 0.8813 - val_loss: 1.3594 - val_accuracy: 0.6852\n",
            "Epoch 142/500\n",
            "3/3 [==============================] - 2s 593ms/step - loss: 0.3727 - accuracy: 0.8828 - val_loss: 1.4261 - val_accuracy: 0.6804\n",
            "Epoch 143/500\n",
            "3/3 [==============================] - 2s 599ms/step - loss: 0.3725 - accuracy: 0.8825 - val_loss: 1.3820 - val_accuracy: 0.6878\n",
            "Epoch 144/500\n",
            "3/3 [==============================] - 2s 716ms/step - loss: 0.3689 - accuracy: 0.8839 - val_loss: 1.4659 - val_accuracy: 0.6796\n",
            "Epoch 145/500\n",
            "3/3 [==============================] - 2s 599ms/step - loss: 0.3718 - accuracy: 0.8809 - val_loss: 1.4269 - val_accuracy: 0.6839\n",
            "Epoch 146/500\n",
            "3/3 [==============================] - 2s 595ms/step - loss: 0.3701 - accuracy: 0.8842 - val_loss: 1.4183 - val_accuracy: 0.6801\n",
            "Epoch 147/500\n",
            "3/3 [==============================] - 2s 596ms/step - loss: 0.3705 - accuracy: 0.8830 - val_loss: 1.3330 - val_accuracy: 0.6890\n",
            "Epoch 148/500\n",
            "3/3 [==============================] - 2s 605ms/step - loss: 0.3701 - accuracy: 0.8840 - val_loss: 1.3734 - val_accuracy: 0.6870\n",
            "Epoch 149/500\n",
            "3/3 [==============================] - 2s 596ms/step - loss: 0.3695 - accuracy: 0.8832 - val_loss: 1.3954 - val_accuracy: 0.6829\n",
            "Epoch 150/500\n",
            "3/3 [==============================] - 2s 869ms/step - loss: 0.3674 - accuracy: 0.8859 - val_loss: 1.3467 - val_accuracy: 0.6847\n",
            "Epoch 151/500\n",
            "3/3 [==============================] - 2s 630ms/step - loss: 0.3658 - accuracy: 0.8832 - val_loss: 1.3902 - val_accuracy: 0.6819\n",
            "Epoch 152/500\n",
            "3/3 [==============================] - 2s 923ms/step - loss: 0.3641 - accuracy: 0.8839 - val_loss: 1.3470 - val_accuracy: 0.6845\n",
            "Epoch 153/500\n",
            "3/3 [==============================] - 3s 1s/step - loss: 0.3639 - accuracy: 0.8848 - val_loss: 1.3812 - val_accuracy: 0.6817\n",
            "Epoch 154/500\n",
            "3/3 [==============================] - 4s 2s/step - loss: 0.3707 - accuracy: 0.8855 - val_loss: 1.3556 - val_accuracy: 0.6832\n",
            "Epoch 155/500\n",
            "3/3 [==============================] - 3s 1s/step - loss: 0.3634 - accuracy: 0.8834 - val_loss: 1.3119 - val_accuracy: 0.6895\n",
            "Epoch 156/500\n",
            "3/3 [==============================] - 3s 1s/step - loss: 0.3654 - accuracy: 0.8830 - val_loss: 1.3587 - val_accuracy: 0.6862\n",
            "Epoch 157/500\n",
            "3/3 [==============================] - 3s 849ms/step - loss: 0.3609 - accuracy: 0.8867 - val_loss: 1.3372 - val_accuracy: 0.6870\n",
            "Epoch 158/500\n",
            "3/3 [==============================] - 2s 830ms/step - loss: 0.3607 - accuracy: 0.8842 - val_loss: 1.3380 - val_accuracy: 0.6850\n",
            "Epoch 159/500\n",
            "3/3 [==============================] - 2s 606ms/step - loss: 0.3580 - accuracy: 0.8874 - val_loss: 1.3686 - val_accuracy: 0.6870\n",
            "Epoch 160/500\n",
            "3/3 [==============================] - 2s 592ms/step - loss: 0.3579 - accuracy: 0.8848 - val_loss: 1.3435 - val_accuracy: 0.6855\n",
            "Epoch 161/500\n",
            "3/3 [==============================] - 2s 603ms/step - loss: 0.3614 - accuracy: 0.8876 - val_loss: 1.3036 - val_accuracy: 0.6855\n",
            "Epoch 162/500\n",
            "3/3 [==============================] - 2s 592ms/step - loss: 0.3580 - accuracy: 0.8875 - val_loss: 1.3930 - val_accuracy: 0.6804\n",
            "Epoch 163/500\n",
            "3/3 [==============================] - 2s 592ms/step - loss: 0.3622 - accuracy: 0.8850 - val_loss: 1.3465 - val_accuracy: 0.6862\n",
            "Epoch 164/500\n",
            "3/3 [==============================] - 2s 853ms/step - loss: 0.3550 - accuracy: 0.8868 - val_loss: 1.3452 - val_accuracy: 0.6842\n",
            "Epoch 165/500\n",
            "3/3 [==============================] - 2s 659ms/step - loss: 0.3570 - accuracy: 0.8857 - val_loss: 1.3613 - val_accuracy: 0.6865\n",
            "Epoch 166/500\n",
            "3/3 [==============================] - 3s 915ms/step - loss: 0.3572 - accuracy: 0.8863 - val_loss: 1.3714 - val_accuracy: 0.6847\n",
            "Epoch 167/500\n",
            "3/3 [==============================] - 3s 944ms/step - loss: 0.3528 - accuracy: 0.8885 - val_loss: 1.3700 - val_accuracy: 0.6847\n",
            "Epoch 168/500\n",
            "3/3 [==============================] - 2s 605ms/step - loss: 0.3537 - accuracy: 0.8882 - val_loss: 1.3457 - val_accuracy: 0.6834\n",
            "Epoch 169/500\n",
            "3/3 [==============================] - 2s 889ms/step - loss: 0.3637 - accuracy: 0.8881 - val_loss: 1.3789 - val_accuracy: 0.6814\n",
            "Epoch 170/500\n",
            "3/3 [==============================] - 2s 601ms/step - loss: 0.3708 - accuracy: 0.8838 - val_loss: 1.3042 - val_accuracy: 0.6857\n",
            "Epoch 171/500\n",
            "3/3 [==============================] - 2s 600ms/step - loss: 0.3556 - accuracy: 0.8870 - val_loss: 1.2774 - val_accuracy: 0.6875\n",
            "Epoch 172/500\n",
            "3/3 [==============================] - 2s 609ms/step - loss: 0.3477 - accuracy: 0.8866 - val_loss: 1.4483 - val_accuracy: 0.6819\n",
            "Epoch 173/500\n",
            "3/3 [==============================] - 2s 597ms/step - loss: 0.3497 - accuracy: 0.8878 - val_loss: 1.3609 - val_accuracy: 0.6827\n",
            "Epoch 174/500\n",
            "3/3 [==============================] - 2s 599ms/step - loss: 0.3458 - accuracy: 0.8890 - val_loss: 1.2691 - val_accuracy: 0.6913\n",
            "Epoch 175/500\n",
            "3/3 [==============================] - 2s 832ms/step - loss: 0.3494 - accuracy: 0.8880 - val_loss: 1.3249 - val_accuracy: 0.6888\n",
            "Epoch 176/500\n",
            "3/3 [==============================] - 2s 602ms/step - loss: 0.3490 - accuracy: 0.8867 - val_loss: 1.3385 - val_accuracy: 0.6822\n",
            "Epoch 177/500\n",
            "3/3 [==============================] - 2s 609ms/step - loss: 0.3473 - accuracy: 0.8894 - val_loss: 1.3471 - val_accuracy: 0.6847\n",
            "Epoch 178/500\n",
            "3/3 [==============================] - 2s 602ms/step - loss: 0.3492 - accuracy: 0.8894 - val_loss: 1.3296 - val_accuracy: 0.6880\n",
            "Epoch 179/500\n",
            "3/3 [==============================] - 2s 610ms/step - loss: 0.3474 - accuracy: 0.8891 - val_loss: 1.3449 - val_accuracy: 0.6827\n",
            "Epoch 180/500\n",
            "3/3 [==============================] - 2s 606ms/step - loss: 0.3542 - accuracy: 0.8898 - val_loss: 1.3577 - val_accuracy: 0.6837\n",
            "Epoch 181/500\n",
            "3/3 [==============================] - 2s 818ms/step - loss: 0.3505 - accuracy: 0.8887 - val_loss: 1.3052 - val_accuracy: 0.6842\n",
            "Epoch 182/500\n",
            "3/3 [==============================] - 2s 605ms/step - loss: 0.3654 - accuracy: 0.8856 - val_loss: 1.3754 - val_accuracy: 0.6735\n",
            "Epoch 183/500\n",
            "3/3 [==============================] - 2s 608ms/step - loss: 0.3791 - accuracy: 0.8812 - val_loss: 1.9293 - val_accuracy: 0.6839\n",
            "Epoch 184/500\n",
            "3/3 [==============================] - 2s 593ms/step - loss: 0.4068 - accuracy: 0.8727 - val_loss: 1.2745 - val_accuracy: 0.6895\n",
            "Epoch 185/500\n",
            "3/3 [==============================] - 2s 617ms/step - loss: 0.3906 - accuracy: 0.8747 - val_loss: 1.3735 - val_accuracy: 0.6809\n",
            "Epoch 186/500\n",
            "3/3 [==============================] - 2s 595ms/step - loss: 0.3869 - accuracy: 0.8773 - val_loss: 1.1981 - val_accuracy: 0.6994\n",
            "Epoch 187/500\n",
            "3/3 [==============================] - 2s 774ms/step - loss: 0.3805 - accuracy: 0.8799 - val_loss: 1.2550 - val_accuracy: 0.6984\n",
            "Epoch 188/500\n",
            "3/3 [==============================] - 2s 603ms/step - loss: 0.3740 - accuracy: 0.8820 - val_loss: 1.3786 - val_accuracy: 0.6900\n",
            "Epoch 189/500\n",
            "3/3 [==============================] - 2s 609ms/step - loss: 0.3705 - accuracy: 0.8813 - val_loss: 1.2571 - val_accuracy: 0.6949\n",
            "Epoch 190/500\n",
            "3/3 [==============================] - 2s 599ms/step - loss: 0.3629 - accuracy: 0.8844 - val_loss: 1.2887 - val_accuracy: 0.6972\n",
            "Epoch 191/500\n",
            "3/3 [==============================] - 2s 594ms/step - loss: 0.3598 - accuracy: 0.8841 - val_loss: 1.3667 - val_accuracy: 0.6905\n",
            "Epoch 192/500\n",
            "3/3 [==============================] - 2s 600ms/step - loss: 0.3566 - accuracy: 0.8853 - val_loss: 1.3834 - val_accuracy: 0.6885\n",
            "Epoch 193/500\n",
            "3/3 [==============================] - 2s 744ms/step - loss: 0.3510 - accuracy: 0.8863 - val_loss: 1.4420 - val_accuracy: 0.6885\n",
            "Epoch 194/500\n",
            "3/3 [==============================] - 2s 599ms/step - loss: 0.3495 - accuracy: 0.8870 - val_loss: 1.4430 - val_accuracy: 0.6883\n",
            "Epoch 195/500\n",
            "3/3 [==============================] - 2s 598ms/step - loss: 0.3474 - accuracy: 0.8890 - val_loss: 1.4569 - val_accuracy: 0.6883\n",
            "Epoch 196/500\n",
            "3/3 [==============================] - 2s 600ms/step - loss: 0.3527 - accuracy: 0.8887 - val_loss: 1.5325 - val_accuracy: 0.6822\n",
            "Epoch 197/500\n",
            "3/3 [==============================] - 2s 595ms/step - loss: 0.3505 - accuracy: 0.8894 - val_loss: 1.6101 - val_accuracy: 0.6827\n",
            "Epoch 198/500\n",
            "3/3 [==============================] - 2s 604ms/step - loss: 0.3510 - accuracy: 0.8892 - val_loss: 1.6408 - val_accuracy: 0.6847\n",
            "Epoch 199/500\n",
            "3/3 [==============================] - 2s 689ms/step - loss: 0.3421 - accuracy: 0.8900 - val_loss: 1.5041 - val_accuracy: 0.6880\n",
            "Epoch 200/500\n",
            "3/3 [==============================] - 2s 596ms/step - loss: 0.3396 - accuracy: 0.8903 - val_loss: 1.5656 - val_accuracy: 0.6842\n",
            "Epoch 201/500\n",
            "3/3 [==============================] - 2s 604ms/step - loss: 0.3414 - accuracy: 0.8891 - val_loss: 1.6256 - val_accuracy: 0.6865\n",
            "Epoch 202/500\n",
            "3/3 [==============================] - 2s 599ms/step - loss: 0.3392 - accuracy: 0.8914 - val_loss: 1.5504 - val_accuracy: 0.6875\n",
            "Epoch 203/500\n",
            "3/3 [==============================] - 2s 602ms/step - loss: 0.3365 - accuracy: 0.8924 - val_loss: 1.5417 - val_accuracy: 0.6867\n",
            "Epoch 204/500\n",
            "3/3 [==============================] - 2s 606ms/step - loss: 0.3355 - accuracy: 0.8921 - val_loss: 1.5080 - val_accuracy: 0.6824\n",
            "Epoch 205/500\n",
            "3/3 [==============================] - 2s 712ms/step - loss: 0.3335 - accuracy: 0.8917 - val_loss: 1.5449 - val_accuracy: 0.6850\n",
            "Epoch 206/500\n",
            "3/3 [==============================] - 2s 606ms/step - loss: 0.3341 - accuracy: 0.8930 - val_loss: 1.5117 - val_accuracy: 0.6880\n",
            "Epoch 207/500\n",
            "3/3 [==============================] - 2s 591ms/step - loss: 0.3336 - accuracy: 0.8926 - val_loss: 1.5171 - val_accuracy: 0.6832\n",
            "Epoch 208/500\n",
            "3/3 [==============================] - 2s 589ms/step - loss: 0.3353 - accuracy: 0.8917 - val_loss: 1.4707 - val_accuracy: 0.6893\n",
            "Epoch 209/500\n",
            "3/3 [==============================] - 2s 606ms/step - loss: 0.3335 - accuracy: 0.8911 - val_loss: 1.5980 - val_accuracy: 0.6819\n",
            "Epoch 210/500\n",
            "3/3 [==============================] - 2s 617ms/step - loss: 0.3351 - accuracy: 0.8924 - val_loss: 1.4710 - val_accuracy: 0.6850\n",
            "Epoch 211/500\n",
            "3/3 [==============================] - 2s 709ms/step - loss: 0.3331 - accuracy: 0.8930 - val_loss: 1.5445 - val_accuracy: 0.6885\n",
            "Epoch 212/500\n",
            "3/3 [==============================] - 2s 608ms/step - loss: 0.3320 - accuracy: 0.8926 - val_loss: 1.5349 - val_accuracy: 0.6847\n",
            "Epoch 213/500\n",
            "3/3 [==============================] - 2s 604ms/step - loss: 0.3298 - accuracy: 0.8936 - val_loss: 1.5504 - val_accuracy: 0.6860\n",
            "Epoch 214/500\n",
            "3/3 [==============================] - 2s 596ms/step - loss: 0.3279 - accuracy: 0.8947 - val_loss: 1.5607 - val_accuracy: 0.6862\n",
            "Epoch 215/500\n",
            "3/3 [==============================] - 2s 605ms/step - loss: 0.3331 - accuracy: 0.8960 - val_loss: 1.5933 - val_accuracy: 0.6847\n",
            "Epoch 216/500\n",
            "3/3 [==============================] - 2s 774ms/step - loss: 0.3248 - accuracy: 0.8950 - val_loss: 1.5235 - val_accuracy: 0.6837\n",
            "Epoch 217/500\n",
            "3/3 [==============================] - 2s 732ms/step - loss: 0.3244 - accuracy: 0.8954 - val_loss: 1.6062 - val_accuracy: 0.6855\n",
            "Epoch 218/500\n",
            "3/3 [==============================] - 2s 604ms/step - loss: 0.3236 - accuracy: 0.8953 - val_loss: 1.5914 - val_accuracy: 0.6839\n",
            "Epoch 219/500\n",
            "3/3 [==============================] - 2s 604ms/step - loss: 0.3254 - accuracy: 0.8958 - val_loss: 1.5914 - val_accuracy: 0.6791\n",
            "Epoch 220/500\n",
            "3/3 [==============================] - 2s 601ms/step - loss: 0.3319 - accuracy: 0.8956 - val_loss: 1.6363 - val_accuracy: 0.6837\n",
            "Epoch 221/500\n",
            "3/3 [==============================] - 2s 596ms/step - loss: 0.3234 - accuracy: 0.8956 - val_loss: 1.5840 - val_accuracy: 0.6852\n",
            "Epoch 222/500\n",
            "3/3 [==============================] - 2s 603ms/step - loss: 0.3339 - accuracy: 0.8951 - val_loss: 1.6101 - val_accuracy: 0.6862\n",
            "Epoch 223/500\n",
            "3/3 [==============================] - 2s 782ms/step - loss: 0.3216 - accuracy: 0.8965 - val_loss: 1.5339 - val_accuracy: 0.6867\n",
            "Epoch 224/500\n",
            "3/3 [==============================] - 2s 598ms/step - loss: 0.3200 - accuracy: 0.8953 - val_loss: 1.6261 - val_accuracy: 0.6839\n",
            "Epoch 225/500\n",
            "3/3 [==============================] - 2s 598ms/step - loss: 0.3232 - accuracy: 0.8962 - val_loss: 1.5571 - val_accuracy: 0.6852\n",
            "Epoch 226/500\n",
            "3/3 [==============================] - 2s 605ms/step - loss: 0.3171 - accuracy: 0.8975 - val_loss: 1.5919 - val_accuracy: 0.6827\n",
            "Epoch 227/500\n",
            "3/3 [==============================] - 2s 605ms/step - loss: 0.3147 - accuracy: 0.8981 - val_loss: 1.5643 - val_accuracy: 0.6870\n",
            "Epoch 228/500\n",
            "3/3 [==============================] - 2s 595ms/step - loss: 0.3158 - accuracy: 0.8980 - val_loss: 1.6081 - val_accuracy: 0.6842\n",
            "Epoch 229/500\n",
            "3/3 [==============================] - 2s 707ms/step - loss: 0.3150 - accuracy: 0.8986 - val_loss: 1.5805 - val_accuracy: 0.6817\n",
            "Epoch 230/500\n",
            "3/3 [==============================] - 2s 605ms/step - loss: 0.3162 - accuracy: 0.8968 - val_loss: 1.5312 - val_accuracy: 0.6900\n",
            "Epoch 231/500\n",
            "3/3 [==============================] - 2s 606ms/step - loss: 0.3169 - accuracy: 0.8973 - val_loss: 1.5693 - val_accuracy: 0.6839\n",
            "Epoch 232/500\n",
            "3/3 [==============================] - 2s 598ms/step - loss: 0.3160 - accuracy: 0.8980 - val_loss: 1.5626 - val_accuracy: 0.6796\n",
            "Epoch 233/500\n",
            "3/3 [==============================] - 2s 604ms/step - loss: 0.3180 - accuracy: 0.8986 - val_loss: 1.4956 - val_accuracy: 0.6824\n",
            "Epoch 234/500\n",
            "3/3 [==============================] - 2s 597ms/step - loss: 0.3226 - accuracy: 0.8960 - val_loss: 1.5974 - val_accuracy: 0.6817\n",
            "Epoch 235/500\n",
            "3/3 [==============================] - 2s 741ms/step - loss: 0.3420 - accuracy: 0.8960 - val_loss: 1.5175 - val_accuracy: 0.6837\n",
            "Epoch 236/500\n",
            "3/3 [==============================] - 2s 604ms/step - loss: 0.3236 - accuracy: 0.8969 - val_loss: 1.4613 - val_accuracy: 0.6870\n",
            "Epoch 237/500\n",
            "3/3 [==============================] - 2s 595ms/step - loss: 0.3157 - accuracy: 0.8973 - val_loss: 1.5104 - val_accuracy: 0.6834\n",
            "Epoch 238/500\n",
            "3/3 [==============================] - 2s 598ms/step - loss: 0.3124 - accuracy: 0.8981 - val_loss: 1.5808 - val_accuracy: 0.6865\n",
            "Epoch 239/500\n",
            "3/3 [==============================] - 2s 599ms/step - loss: 0.3116 - accuracy: 0.8986 - val_loss: 1.6778 - val_accuracy: 0.6857\n",
            "Epoch 240/500\n",
            "3/3 [==============================] - 2s 592ms/step - loss: 0.3102 - accuracy: 0.8987 - val_loss: 1.5487 - val_accuracy: 0.6809\n",
            "Epoch 241/500\n",
            "3/3 [==============================] - 2s 718ms/step - loss: 0.3070 - accuracy: 0.9005 - val_loss: 1.6333 - val_accuracy: 0.6829\n",
            "Epoch 242/500\n",
            "3/3 [==============================] - 3s 836ms/step - loss: 0.3053 - accuracy: 0.9024 - val_loss: 1.5278 - val_accuracy: 0.6822\n",
            "Epoch 243/500\n",
            "3/3 [==============================] - 2s 607ms/step - loss: 0.3041 - accuracy: 0.9022 - val_loss: 1.5201 - val_accuracy: 0.6827\n",
            "Epoch 244/500\n",
            "3/3 [==============================] - 2s 606ms/step - loss: 0.3050 - accuracy: 0.9007 - val_loss: 1.5969 - val_accuracy: 0.6855\n",
            "Epoch 245/500\n",
            "3/3 [==============================] - 2s 606ms/step - loss: 0.3058 - accuracy: 0.9015 - val_loss: 1.4859 - val_accuracy: 0.6829\n",
            "Epoch 246/500\n",
            "3/3 [==============================] - 2s 591ms/step - loss: 0.3070 - accuracy: 0.9005 - val_loss: 1.5946 - val_accuracy: 0.6809\n",
            "Epoch 247/500\n",
            "3/3 [==============================] - 2s 605ms/step - loss: 0.3060 - accuracy: 0.9025 - val_loss: 1.5495 - val_accuracy: 0.6872\n",
            "Epoch 248/500\n",
            "3/3 [==============================] - 2s 777ms/step - loss: 0.3065 - accuracy: 0.9019 - val_loss: 1.5773 - val_accuracy: 0.6791\n",
            "Epoch 249/500\n",
            "3/3 [==============================] - 2s 601ms/step - loss: 0.3169 - accuracy: 0.8978 - val_loss: 1.5399 - val_accuracy: 0.6855\n",
            "Epoch 250/500\n",
            "3/3 [==============================] - 2s 590ms/step - loss: 0.3107 - accuracy: 0.8986 - val_loss: 1.5142 - val_accuracy: 0.6872\n",
            "Epoch 251/500\n",
            "3/3 [==============================] - 2s 590ms/step - loss: 0.3214 - accuracy: 0.8977 - val_loss: 1.4477 - val_accuracy: 0.6837\n",
            "Epoch 252/500\n",
            "3/3 [==============================] - 2s 605ms/step - loss: 0.3129 - accuracy: 0.8984 - val_loss: 1.5554 - val_accuracy: 0.6890\n",
            "Epoch 253/500\n",
            "3/3 [==============================] - 2s 613ms/step - loss: 0.3135 - accuracy: 0.8974 - val_loss: 1.6323 - val_accuracy: 0.6786\n",
            "Epoch 254/500\n",
            "3/3 [==============================] - 2s 823ms/step - loss: 0.3104 - accuracy: 0.8984 - val_loss: 1.5074 - val_accuracy: 0.6850\n",
            "Epoch 255/500\n",
            "3/3 [==============================] - 2s 597ms/step - loss: 0.3073 - accuracy: 0.9003 - val_loss: 1.6392 - val_accuracy: 0.6855\n",
            "Epoch 256/500\n",
            "3/3 [==============================] - 2s 605ms/step - loss: 0.3033 - accuracy: 0.9007 - val_loss: 1.5579 - val_accuracy: 0.6842\n",
            "Epoch 257/500\n",
            "3/3 [==============================] - 2s 596ms/step - loss: 0.3040 - accuracy: 0.9026 - val_loss: 1.5363 - val_accuracy: 0.6855\n",
            "Epoch 258/500\n",
            "3/3 [==============================] - 2s 612ms/step - loss: 0.3001 - accuracy: 0.9018 - val_loss: 1.6850 - val_accuracy: 0.6804\n",
            "Epoch 259/500\n",
            "3/3 [==============================] - 2s 596ms/step - loss: 0.3054 - accuracy: 0.9030 - val_loss: 1.5134 - val_accuracy: 0.6893\n",
            "Epoch 260/500\n",
            "3/3 [==============================] - 2s 820ms/step - loss: 0.3026 - accuracy: 0.9014 - val_loss: 1.6285 - val_accuracy: 0.6867\n",
            "Epoch 261/500\n",
            "3/3 [==============================] - 2s 600ms/step - loss: 0.2989 - accuracy: 0.9031 - val_loss: 1.5926 - val_accuracy: 0.6865\n",
            "Epoch 262/500\n",
            "3/3 [==============================] - 2s 622ms/step - loss: 0.3012 - accuracy: 0.9033 - val_loss: 1.5175 - val_accuracy: 0.6857\n",
            "Epoch 263/500\n",
            "3/3 [==============================] - 2s 606ms/step - loss: 0.2946 - accuracy: 0.9056 - val_loss: 1.6042 - val_accuracy: 0.6834\n",
            "Epoch 264/500\n",
            "3/3 [==============================] - 2s 608ms/step - loss: 0.2926 - accuracy: 0.9045 - val_loss: 1.5838 - val_accuracy: 0.6857\n",
            "Epoch 265/500\n",
            "3/3 [==============================] - 2s 605ms/step - loss: 0.2935 - accuracy: 0.9053 - val_loss: 1.5503 - val_accuracy: 0.6842\n",
            "Epoch 266/500\n",
            "3/3 [==============================] - 2s 859ms/step - loss: 0.2908 - accuracy: 0.9063 - val_loss: 1.6148 - val_accuracy: 0.6814\n",
            "Epoch 267/500\n",
            "3/3 [==============================] - 2s 602ms/step - loss: 0.2898 - accuracy: 0.9047 - val_loss: 1.5566 - val_accuracy: 0.6883\n",
            "Epoch 268/500\n",
            "3/3 [==============================] - 2s 605ms/step - loss: 0.2921 - accuracy: 0.9053 - val_loss: 1.5652 - val_accuracy: 0.6855\n",
            "Epoch 269/500\n",
            "3/3 [==============================] - 2s 593ms/step - loss: 0.2920 - accuracy: 0.9051 - val_loss: 1.5317 - val_accuracy: 0.6837\n",
            "Epoch 270/500\n",
            "3/3 [==============================] - 2s 594ms/step - loss: 0.2910 - accuracy: 0.9066 - val_loss: 1.5890 - val_accuracy: 0.6824\n",
            "Epoch 271/500\n",
            "3/3 [==============================] - 2s 601ms/step - loss: 0.2993 - accuracy: 0.9054 - val_loss: 1.4989 - val_accuracy: 0.6829\n",
            "Epoch 272/500\n",
            "3/3 [==============================] - 2s 794ms/step - loss: 0.2937 - accuracy: 0.9081 - val_loss: 1.6323 - val_accuracy: 0.6832\n",
            "Epoch 273/500\n",
            "3/3 [==============================] - 2s 612ms/step - loss: 0.2963 - accuracy: 0.9066 - val_loss: 1.5278 - val_accuracy: 0.6845\n",
            "Epoch 274/500\n",
            "3/3 [==============================] - 2s 606ms/step - loss: 0.2837 - accuracy: 0.9066 - val_loss: 1.5158 - val_accuracy: 0.6852\n",
            "Epoch 275/500\n",
            "3/3 [==============================] - 2s 769ms/step - loss: 0.2860 - accuracy: 0.9063 - val_loss: 1.5491 - val_accuracy: 0.6809\n",
            "Epoch 276/500\n",
            "3/3 [==============================] - 2s 602ms/step - loss: 0.2868 - accuracy: 0.9071 - val_loss: 1.5428 - val_accuracy: 0.6806\n",
            "Epoch 277/500\n",
            "3/3 [==============================] - 2s 596ms/step - loss: 0.2817 - accuracy: 0.9072 - val_loss: 1.5253 - val_accuracy: 0.6819\n",
            "Epoch 278/500\n",
            "3/3 [==============================] - 2s 837ms/step - loss: 0.2850 - accuracy: 0.9068 - val_loss: 1.5657 - val_accuracy: 0.6809\n",
            "Epoch 279/500\n",
            "3/3 [==============================] - 2s 603ms/step - loss: 0.2847 - accuracy: 0.9072 - val_loss: 1.5646 - val_accuracy: 0.6804\n",
            "Epoch 280/500\n",
            "3/3 [==============================] - 2s 609ms/step - loss: 0.2828 - accuracy: 0.9072 - val_loss: 1.6152 - val_accuracy: 0.6839\n",
            "Epoch 281/500\n",
            "3/3 [==============================] - 2s 600ms/step - loss: 0.2830 - accuracy: 0.9083 - val_loss: 1.4717 - val_accuracy: 0.6832\n",
            "Epoch 282/500\n",
            "3/3 [==============================] - 2s 608ms/step - loss: 0.2820 - accuracy: 0.9085 - val_loss: 1.5079 - val_accuracy: 0.6860\n",
            "Epoch 283/500\n",
            "3/3 [==============================] - 2s 610ms/step - loss: 0.2831 - accuracy: 0.9081 - val_loss: 1.5195 - val_accuracy: 0.6819\n",
            "Epoch 284/500\n",
            "3/3 [==============================] - 2s 881ms/step - loss: 0.2834 - accuracy: 0.9075 - val_loss: 1.5302 - val_accuracy: 0.6855\n",
            "Epoch 285/500\n",
            "3/3 [==============================] - 2s 656ms/step - loss: 0.2808 - accuracy: 0.9089 - val_loss: 1.5485 - val_accuracy: 0.6781\n",
            "Epoch 286/500\n",
            "3/3 [==============================] - 2s 594ms/step - loss: 0.2824 - accuracy: 0.9094 - val_loss: 1.5652 - val_accuracy: 0.6796\n",
            "Epoch 287/500\n",
            "3/3 [==============================] - 2s 599ms/step - loss: 0.2935 - accuracy: 0.9094 - val_loss: 1.5425 - val_accuracy: 0.6855\n",
            "Epoch 288/500\n",
            "3/3 [==============================] - 2s 601ms/step - loss: 0.2796 - accuracy: 0.9107 - val_loss: 1.6025 - val_accuracy: 0.6804\n",
            "Epoch 289/500\n",
            "3/3 [==============================] - 2s 607ms/step - loss: 0.2812 - accuracy: 0.9086 - val_loss: 1.5015 - val_accuracy: 0.6839\n",
            "Epoch 290/500\n",
            "3/3 [==============================] - 2s 825ms/step - loss: 0.2782 - accuracy: 0.9111 - val_loss: 1.4943 - val_accuracy: 0.6829\n",
            "Epoch 291/500\n",
            "3/3 [==============================] - 2s 602ms/step - loss: 0.2782 - accuracy: 0.9094 - val_loss: 1.5191 - val_accuracy: 0.6809\n",
            "Epoch 292/500\n",
            "3/3 [==============================] - 2s 608ms/step - loss: 0.2755 - accuracy: 0.9109 - val_loss: 1.6121 - val_accuracy: 0.6791\n",
            "Epoch 293/500\n",
            "3/3 [==============================] - 2s 603ms/step - loss: 0.2749 - accuracy: 0.9104 - val_loss: 1.5514 - val_accuracy: 0.6834\n",
            "Epoch 294/500\n",
            "3/3 [==============================] - 2s 601ms/step - loss: 0.2771 - accuracy: 0.9088 - val_loss: 1.5639 - val_accuracy: 0.6862\n",
            "Epoch 295/500\n",
            "3/3 [==============================] - 2s 608ms/step - loss: 0.2778 - accuracy: 0.9109 - val_loss: 1.5002 - val_accuracy: 0.6845\n",
            "Epoch 296/500\n",
            "3/3 [==============================] - 2s 865ms/step - loss: 0.2784 - accuracy: 0.9092 - val_loss: 1.4971 - val_accuracy: 0.6834\n",
            "Epoch 297/500\n",
            "3/3 [==============================] - 2s 598ms/step - loss: 0.2734 - accuracy: 0.9118 - val_loss: 1.5273 - val_accuracy: 0.6796\n",
            "Epoch 298/500\n",
            "3/3 [==============================] - 2s 598ms/step - loss: 0.2713 - accuracy: 0.9120 - val_loss: 1.5240 - val_accuracy: 0.6832\n",
            "Epoch 299/500\n",
            "3/3 [==============================] - 2s 603ms/step - loss: 0.2728 - accuracy: 0.9117 - val_loss: 1.5075 - val_accuracy: 0.6811\n",
            "Epoch 300/500\n",
            "3/3 [==============================] - 2s 599ms/step - loss: 0.2728 - accuracy: 0.9117 - val_loss: 1.5682 - val_accuracy: 0.6809\n",
            "Epoch 301/500\n",
            "3/3 [==============================] - 2s 597ms/step - loss: 0.2721 - accuracy: 0.9133 - val_loss: 1.5946 - val_accuracy: 0.6819\n",
            "Epoch 302/500\n",
            "3/3 [==============================] - 2s 854ms/step - loss: 0.2684 - accuracy: 0.9120 - val_loss: 1.5556 - val_accuracy: 0.6768\n",
            "Epoch 303/500\n",
            "3/3 [==============================] - 2s 605ms/step - loss: 0.2714 - accuracy: 0.9113 - val_loss: 1.5271 - val_accuracy: 0.6829\n",
            "Epoch 304/500\n",
            "3/3 [==============================] - 2s 609ms/step - loss: 0.2678 - accuracy: 0.9126 - val_loss: 1.5199 - val_accuracy: 0.6796\n",
            "Epoch 305/500\n",
            "3/3 [==============================] - 2s 601ms/step - loss: 0.2645 - accuracy: 0.9130 - val_loss: 1.5352 - val_accuracy: 0.6862\n",
            "Epoch 306/500\n",
            "3/3 [==============================] - 2s 592ms/step - loss: 0.2655 - accuracy: 0.9132 - val_loss: 1.5129 - val_accuracy: 0.6817\n",
            "Epoch 307/500\n",
            "3/3 [==============================] - 2s 610ms/step - loss: 0.2636 - accuracy: 0.9141 - val_loss: 1.6043 - val_accuracy: 0.6817\n",
            "Epoch 308/500\n",
            "3/3 [==============================] - 2s 865ms/step - loss: 0.2659 - accuracy: 0.9152 - val_loss: 1.5366 - val_accuracy: 0.6878\n",
            "Epoch 309/500\n",
            "3/3 [==============================] - 2s 607ms/step - loss: 0.2692 - accuracy: 0.9124 - val_loss: 1.5823 - val_accuracy: 0.6842\n",
            "Epoch 310/500\n",
            "3/3 [==============================] - 2s 597ms/step - loss: 0.2704 - accuracy: 0.9125 - val_loss: 1.5381 - val_accuracy: 0.6878\n",
            "Epoch 311/500\n",
            "3/3 [==============================] - 2s 606ms/step - loss: 0.2652 - accuracy: 0.9127 - val_loss: 1.5236 - val_accuracy: 0.6852\n",
            "Epoch 312/500\n",
            "3/3 [==============================] - 2s 596ms/step - loss: 0.2634 - accuracy: 0.9130 - val_loss: 1.6660 - val_accuracy: 0.6832\n",
            "Epoch 313/500\n",
            "3/3 [==============================] - 2s 597ms/step - loss: 0.2665 - accuracy: 0.9128 - val_loss: 1.5527 - val_accuracy: 0.6832\n",
            "Epoch 314/500\n",
            "3/3 [==============================] - 2s 796ms/step - loss: 0.2643 - accuracy: 0.9152 - val_loss: 1.6351 - val_accuracy: 0.6827\n",
            "Epoch 315/500\n",
            "3/3 [==============================] - 2s 607ms/step - loss: 0.2831 - accuracy: 0.9115 - val_loss: 1.5178 - val_accuracy: 0.6890\n",
            "Epoch 316/500\n",
            "3/3 [==============================] - 2s 602ms/step - loss: 0.2645 - accuracy: 0.9113 - val_loss: 1.5716 - val_accuracy: 0.6763\n",
            "Epoch 317/500\n",
            "3/3 [==============================] - 2s 604ms/step - loss: 0.2669 - accuracy: 0.9123 - val_loss: 1.6678 - val_accuracy: 0.6865\n",
            "Epoch 318/500\n",
            "3/3 [==============================] - 2s 595ms/step - loss: 0.2624 - accuracy: 0.9135 - val_loss: 1.5437 - val_accuracy: 0.6794\n",
            "Epoch 319/500\n",
            "3/3 [==============================] - 2s 601ms/step - loss: 0.2559 - accuracy: 0.9159 - val_loss: 1.5535 - val_accuracy: 0.6850\n",
            "Epoch 320/500\n",
            "3/3 [==============================] - 2s 823ms/step - loss: 0.2571 - accuracy: 0.9155 - val_loss: 1.5910 - val_accuracy: 0.6857\n",
            "Epoch 321/500\n",
            "3/3 [==============================] - 2s 595ms/step - loss: 0.2547 - accuracy: 0.9176 - val_loss: 1.5724 - val_accuracy: 0.6824\n",
            "Epoch 322/500\n",
            "3/3 [==============================] - 2s 594ms/step - loss: 0.2513 - accuracy: 0.9184 - val_loss: 1.6065 - val_accuracy: 0.6852\n",
            "Epoch 323/500\n",
            "3/3 [==============================] - 2s 608ms/step - loss: 0.2529 - accuracy: 0.9189 - val_loss: 1.5789 - val_accuracy: 0.6829\n",
            "Epoch 324/500\n",
            "3/3 [==============================] - 2s 607ms/step - loss: 0.2502 - accuracy: 0.9182 - val_loss: 1.6487 - val_accuracy: 0.6832\n",
            "Epoch 325/500\n",
            "3/3 [==============================] - 2s 603ms/step - loss: 0.2510 - accuracy: 0.9182 - val_loss: 1.5334 - val_accuracy: 0.6832\n",
            "Epoch 326/500\n",
            "3/3 [==============================] - 2s 802ms/step - loss: 0.2500 - accuracy: 0.9191 - val_loss: 1.5095 - val_accuracy: 0.6834\n",
            "Epoch 327/500\n",
            "3/3 [==============================] - 2s 606ms/step - loss: 0.2491 - accuracy: 0.9183 - val_loss: 1.6023 - val_accuracy: 0.6839\n",
            "Epoch 328/500\n",
            "3/3 [==============================] - 2s 602ms/step - loss: 0.2493 - accuracy: 0.9182 - val_loss: 1.5563 - val_accuracy: 0.6832\n",
            "Epoch 329/500\n",
            "3/3 [==============================] - 2s 593ms/step - loss: 0.2560 - accuracy: 0.9163 - val_loss: 1.5982 - val_accuracy: 0.6829\n",
            "Epoch 330/500\n",
            "3/3 [==============================] - 2s 594ms/step - loss: 0.2612 - accuracy: 0.9157 - val_loss: 1.6095 - val_accuracy: 0.6829\n",
            "Epoch 331/500\n",
            "3/3 [==============================] - 2s 590ms/step - loss: 0.2558 - accuracy: 0.9176 - val_loss: 1.6433 - val_accuracy: 0.6862\n",
            "Epoch 332/500\n",
            "3/3 [==============================] - 2s 801ms/step - loss: 0.2510 - accuracy: 0.9174 - val_loss: 1.6165 - val_accuracy: 0.6796\n",
            "Epoch 333/500\n",
            "3/3 [==============================] - 2s 738ms/step - loss: 0.2505 - accuracy: 0.9182 - val_loss: 1.6756 - val_accuracy: 0.6806\n",
            "Epoch 334/500\n",
            "3/3 [==============================] - 2s 596ms/step - loss: 0.2483 - accuracy: 0.9198 - val_loss: 1.6957 - val_accuracy: 0.6832\n",
            "Epoch 335/500\n",
            "3/3 [==============================] - 2s 603ms/step - loss: 0.2463 - accuracy: 0.9200 - val_loss: 1.6765 - val_accuracy: 0.6824\n",
            "Epoch 336/500\n",
            "3/3 [==============================] - 2s 597ms/step - loss: 0.2440 - accuracy: 0.9199 - val_loss: 1.7649 - val_accuracy: 0.6845\n",
            "Epoch 337/500\n",
            "3/3 [==============================] - 2s 592ms/step - loss: 0.2449 - accuracy: 0.9192 - val_loss: 1.6804 - val_accuracy: 0.6827\n",
            "Epoch 338/500\n",
            "3/3 [==============================] - 2s 843ms/step - loss: 0.2450 - accuracy: 0.9204 - val_loss: 1.7089 - val_accuracy: 0.6855\n",
            "Epoch 339/500\n",
            "3/3 [==============================] - 2s 598ms/step - loss: 0.2429 - accuracy: 0.9194 - val_loss: 1.6841 - val_accuracy: 0.6799\n",
            "Epoch 340/500\n",
            "3/3 [==============================] - 2s 609ms/step - loss: 0.2435 - accuracy: 0.9195 - val_loss: 1.7187 - val_accuracy: 0.6806\n",
            "Epoch 341/500\n",
            "3/3 [==============================] - 2s 609ms/step - loss: 0.2436 - accuracy: 0.9210 - val_loss: 1.6415 - val_accuracy: 0.6811\n",
            "Epoch 342/500\n",
            "3/3 [==============================] - 2s 607ms/step - loss: 0.2410 - accuracy: 0.9219 - val_loss: 1.6501 - val_accuracy: 0.6837\n",
            "Epoch 343/500\n",
            "3/3 [==============================] - 2s 594ms/step - loss: 0.2458 - accuracy: 0.9218 - val_loss: 1.7021 - val_accuracy: 0.6804\n",
            "Epoch 344/500\n",
            "3/3 [==============================] - 2s 839ms/step - loss: 0.2495 - accuracy: 0.9163 - val_loss: 1.6949 - val_accuracy: 0.6789\n",
            "Epoch 345/500\n",
            "3/3 [==============================] - 2s 600ms/step - loss: 0.2476 - accuracy: 0.9180 - val_loss: 1.7176 - val_accuracy: 0.6801\n",
            "Epoch 346/500\n",
            "3/3 [==============================] - 2s 603ms/step - loss: 0.2457 - accuracy: 0.9173 - val_loss: 1.7338 - val_accuracy: 0.6806\n",
            "Epoch 347/500\n",
            "3/3 [==============================] - 2s 609ms/step - loss: 0.2461 - accuracy: 0.9176 - val_loss: 1.5800 - val_accuracy: 0.6870\n",
            "Epoch 348/500\n",
            "3/3 [==============================] - 2s 613ms/step - loss: 0.2507 - accuracy: 0.9174 - val_loss: 1.6515 - val_accuracy: 0.6850\n",
            "Epoch 349/500\n",
            "3/3 [==============================] - 2s 594ms/step - loss: 0.2434 - accuracy: 0.9185 - val_loss: 1.6862 - val_accuracy: 0.6811\n",
            "Epoch 350/500\n",
            "3/3 [==============================] - 2s 773ms/step - loss: 0.2421 - accuracy: 0.9199 - val_loss: 1.6843 - val_accuracy: 0.6811\n",
            "Epoch 351/500\n",
            "3/3 [==============================] - 2s 589ms/step - loss: 0.2419 - accuracy: 0.9181 - val_loss: 1.6602 - val_accuracy: 0.6824\n",
            "Epoch 352/500\n",
            "3/3 [==============================] - 2s 604ms/step - loss: 0.2397 - accuracy: 0.9216 - val_loss: 1.7187 - val_accuracy: 0.6768\n",
            "Epoch 353/500\n",
            "3/3 [==============================] - 2s 608ms/step - loss: 0.2414 - accuracy: 0.9213 - val_loss: 1.6476 - val_accuracy: 0.6850\n",
            "Epoch 354/500\n",
            "3/3 [==============================] - 2s 688ms/step - loss: 0.2509 - accuracy: 0.9200 - val_loss: 1.7691 - val_accuracy: 0.6801\n",
            "Epoch 355/500\n",
            "3/3 [==============================] - 2s 602ms/step - loss: 0.2388 - accuracy: 0.9230 - val_loss: 1.6896 - val_accuracy: 0.6819\n",
            "Epoch 356/500\n",
            "3/3 [==============================] - 2s 887ms/step - loss: 0.2411 - accuracy: 0.9219 - val_loss: 1.7276 - val_accuracy: 0.6839\n",
            "Epoch 357/500\n",
            "3/3 [==============================] - 2s 594ms/step - loss: 0.2364 - accuracy: 0.9206 - val_loss: 1.6707 - val_accuracy: 0.6791\n",
            "Epoch 358/500\n",
            "3/3 [==============================] - 2s 596ms/step - loss: 0.2340 - accuracy: 0.9229 - val_loss: 1.6998 - val_accuracy: 0.6824\n",
            "Epoch 359/500\n",
            "3/3 [==============================] - 2s 601ms/step - loss: 0.2329 - accuracy: 0.9242 - val_loss: 1.6897 - val_accuracy: 0.6817\n",
            "Epoch 360/500\n",
            "3/3 [==============================] - 2s 602ms/step - loss: 0.2302 - accuracy: 0.9228 - val_loss: 1.6776 - val_accuracy: 0.6768\n",
            "Epoch 361/500\n",
            "3/3 [==============================] - 2s 607ms/step - loss: 0.2320 - accuracy: 0.9245 - val_loss: 1.6693 - val_accuracy: 0.6860\n",
            "Epoch 362/500\n",
            "3/3 [==============================] - 2s 901ms/step - loss: 0.2291 - accuracy: 0.9257 - val_loss: 1.5978 - val_accuracy: 0.6799\n",
            "Epoch 363/500\n",
            "3/3 [==============================] - 2s 604ms/step - loss: 0.2300 - accuracy: 0.9245 - val_loss: 1.5968 - val_accuracy: 0.6870\n",
            "Epoch 364/500\n",
            "3/3 [==============================] - 2s 605ms/step - loss: 0.2270 - accuracy: 0.9262 - val_loss: 1.6970 - val_accuracy: 0.6811\n",
            "Epoch 365/500\n",
            "3/3 [==============================] - 2s 607ms/step - loss: 0.2270 - accuracy: 0.9255 - val_loss: 1.6767 - val_accuracy: 0.6806\n",
            "Epoch 366/500\n",
            "3/3 [==============================] - 2s 600ms/step - loss: 0.2309 - accuracy: 0.9258 - val_loss: 1.6514 - val_accuracy: 0.6829\n",
            "Epoch 367/500\n",
            "3/3 [==============================] - 2s 596ms/step - loss: 0.2367 - accuracy: 0.9242 - val_loss: 1.7002 - val_accuracy: 0.6867\n",
            "Epoch 368/500\n",
            "3/3 [==============================] - 2s 812ms/step - loss: 0.2300 - accuracy: 0.9245 - val_loss: 1.6555 - val_accuracy: 0.6819\n",
            "Epoch 369/500\n",
            "3/3 [==============================] - 2s 590ms/step - loss: 0.2332 - accuracy: 0.9239 - val_loss: 1.8859 - val_accuracy: 0.6806\n",
            "Epoch 370/500\n",
            "3/3 [==============================] - 2s 613ms/step - loss: 0.2448 - accuracy: 0.9199 - val_loss: 1.7834 - val_accuracy: 0.6771\n",
            "Epoch 371/500\n",
            "3/3 [==============================] - 2s 592ms/step - loss: 0.2362 - accuracy: 0.9214 - val_loss: 1.8450 - val_accuracy: 0.6827\n",
            "Epoch 372/500\n",
            "3/3 [==============================] - 2s 593ms/step - loss: 0.2366 - accuracy: 0.9213 - val_loss: 1.7474 - val_accuracy: 0.6817\n",
            "Epoch 373/500\n",
            "3/3 [==============================] - 2s 615ms/step - loss: 0.2337 - accuracy: 0.9242 - val_loss: 1.8295 - val_accuracy: 0.6817\n",
            "Epoch 374/500\n",
            "3/3 [==============================] - 2s 846ms/step - loss: 0.2317 - accuracy: 0.9239 - val_loss: 1.8634 - val_accuracy: 0.6811\n",
            "Epoch 375/500\n",
            "3/3 [==============================] - 2s 610ms/step - loss: 0.2281 - accuracy: 0.9232 - val_loss: 1.8733 - val_accuracy: 0.6811\n",
            "Epoch 376/500\n",
            "3/3 [==============================] - 2s 597ms/step - loss: 0.2235 - accuracy: 0.9274 - val_loss: 1.8305 - val_accuracy: 0.6834\n",
            "Epoch 377/500\n",
            "3/3 [==============================] - 2s 593ms/step - loss: 0.2254 - accuracy: 0.9265 - val_loss: 1.8551 - val_accuracy: 0.6817\n",
            "Epoch 378/500\n",
            "3/3 [==============================] - 2s 596ms/step - loss: 0.2202 - accuracy: 0.9279 - val_loss: 1.8721 - val_accuracy: 0.6801\n",
            "Epoch 379/500\n",
            "3/3 [==============================] - 2s 600ms/step - loss: 0.2195 - accuracy: 0.9281 - val_loss: 1.8462 - val_accuracy: 0.6804\n",
            "Epoch 380/500\n",
            "3/3 [==============================] - 2s 841ms/step - loss: 0.2181 - accuracy: 0.9287 - val_loss: 1.7891 - val_accuracy: 0.6796\n",
            "Epoch 381/500\n",
            "3/3 [==============================] - 2s 598ms/step - loss: 0.2192 - accuracy: 0.9276 - val_loss: 1.8179 - val_accuracy: 0.6822\n",
            "Epoch 382/500\n",
            "3/3 [==============================] - 2s 594ms/step - loss: 0.2172 - accuracy: 0.9287 - val_loss: 1.8499 - val_accuracy: 0.6781\n",
            "Epoch 383/500\n",
            "3/3 [==============================] - 2s 594ms/step - loss: 0.2155 - accuracy: 0.9298 - val_loss: 1.8464 - val_accuracy: 0.6822\n",
            "Epoch 384/500\n",
            "3/3 [==============================] - 2s 593ms/step - loss: 0.2148 - accuracy: 0.9302 - val_loss: 1.8591 - val_accuracy: 0.6824\n",
            "Epoch 385/500\n",
            "3/3 [==============================] - 2s 609ms/step - loss: 0.2326 - accuracy: 0.9308 - val_loss: 1.8337 - val_accuracy: 0.6824\n",
            "Epoch 386/500\n",
            "3/3 [==============================] - 2s 762ms/step - loss: 0.2148 - accuracy: 0.9292 - val_loss: 1.8803 - val_accuracy: 0.6824\n",
            "Epoch 387/500\n",
            "3/3 [==============================] - 2s 619ms/step - loss: 0.2273 - accuracy: 0.9281 - val_loss: 1.7570 - val_accuracy: 0.6845\n",
            "Epoch 388/500\n",
            "3/3 [==============================] - 2s 605ms/step - loss: 0.2199 - accuracy: 0.9293 - val_loss: 1.9234 - val_accuracy: 0.6827\n",
            "Epoch 389/500\n",
            "3/3 [==============================] - 2s 597ms/step - loss: 0.2132 - accuracy: 0.9307 - val_loss: 1.8124 - val_accuracy: 0.6809\n",
            "Epoch 390/500\n",
            "3/3 [==============================] - 2s 606ms/step - loss: 0.2141 - accuracy: 0.9309 - val_loss: 1.7842 - val_accuracy: 0.6819\n",
            "Epoch 391/500\n",
            "3/3 [==============================] - 2s 597ms/step - loss: 0.2119 - accuracy: 0.9311 - val_loss: 1.8613 - val_accuracy: 0.6791\n",
            "Epoch 392/500\n",
            "3/3 [==============================] - 2s 732ms/step - loss: 0.2087 - accuracy: 0.9318 - val_loss: 1.7554 - val_accuracy: 0.6814\n",
            "Epoch 393/500\n",
            "3/3 [==============================] - 2s 599ms/step - loss: 0.2113 - accuracy: 0.9320 - val_loss: 1.8595 - val_accuracy: 0.6809\n",
            "Epoch 394/500\n",
            "3/3 [==============================] - 2s 590ms/step - loss: 0.2086 - accuracy: 0.9316 - val_loss: 1.8103 - val_accuracy: 0.6801\n",
            "Epoch 395/500\n",
            "3/3 [==============================] - 2s 614ms/step - loss: 0.2084 - accuracy: 0.9309 - val_loss: 1.7851 - val_accuracy: 0.6862\n",
            "Epoch 396/500\n",
            "3/3 [==============================] - 2s 595ms/step - loss: 0.2087 - accuracy: 0.9315 - val_loss: 1.7966 - val_accuracy: 0.6801\n",
            "Epoch 397/500\n",
            "3/3 [==============================] - 2s 602ms/step - loss: 0.2108 - accuracy: 0.9324 - val_loss: 1.8202 - val_accuracy: 0.6817\n",
            "Epoch 398/500\n",
            "3/3 [==============================] - 2s 761ms/step - loss: 0.2082 - accuracy: 0.9320 - val_loss: 1.7976 - val_accuracy: 0.6834\n",
            "Epoch 399/500\n",
            "3/3 [==============================] - 2s 606ms/step - loss: 0.2055 - accuracy: 0.9341 - val_loss: 1.8781 - val_accuracy: 0.6789\n",
            "Epoch 400/500\n",
            "3/3 [==============================] - 2s 594ms/step - loss: 0.2060 - accuracy: 0.9348 - val_loss: 1.8172 - val_accuracy: 0.6809\n",
            "Epoch 401/500\n",
            "3/3 [==============================] - 2s 602ms/step - loss: 0.2067 - accuracy: 0.9356 - val_loss: 1.8848 - val_accuracy: 0.6824\n",
            "Epoch 402/500\n",
            "3/3 [==============================] - 2s 603ms/step - loss: 0.2084 - accuracy: 0.9346 - val_loss: 1.8284 - val_accuracy: 0.6794\n",
            "Epoch 403/500\n",
            "3/3 [==============================] - 2s 603ms/step - loss: 0.2232 - accuracy: 0.9318 - val_loss: 1.9517 - val_accuracy: 0.6837\n",
            "Epoch 404/500\n",
            "3/3 [==============================] - 2s 748ms/step - loss: 0.2157 - accuracy: 0.9301 - val_loss: 1.7372 - val_accuracy: 0.6811\n",
            "Epoch 405/500\n",
            "3/3 [==============================] - 2s 607ms/step - loss: 0.2102 - accuracy: 0.9312 - val_loss: 1.9094 - val_accuracy: 0.6766\n",
            "Epoch 406/500\n",
            "3/3 [==============================] - 2s 595ms/step - loss: 0.2131 - accuracy: 0.9305 - val_loss: 1.8689 - val_accuracy: 0.6837\n",
            "Epoch 407/500\n",
            "3/3 [==============================] - 2s 613ms/step - loss: 0.2092 - accuracy: 0.9317 - val_loss: 1.9095 - val_accuracy: 0.6811\n",
            "Epoch 408/500\n",
            "3/3 [==============================] - 2s 597ms/step - loss: 0.2049 - accuracy: 0.9335 - val_loss: 1.8971 - val_accuracy: 0.6804\n",
            "Epoch 409/500\n",
            "3/3 [==============================] - 2s 623ms/step - loss: 0.2045 - accuracy: 0.9340 - val_loss: 1.9265 - val_accuracy: 0.6794\n",
            "Epoch 410/500\n",
            "3/3 [==============================] - 2s 715ms/step - loss: 0.2030 - accuracy: 0.9340 - val_loss: 1.8943 - val_accuracy: 0.6817\n",
            "Epoch 411/500\n",
            "3/3 [==============================] - 2s 599ms/step - loss: 0.2010 - accuracy: 0.9340 - val_loss: 1.8512 - val_accuracy: 0.6829\n",
            "Epoch 412/500\n",
            "3/3 [==============================] - 2s 610ms/step - loss: 0.2074 - accuracy: 0.9318 - val_loss: 1.9036 - val_accuracy: 0.6809\n",
            "Epoch 413/500\n",
            "3/3 [==============================] - 2s 589ms/step - loss: 0.2006 - accuracy: 0.9349 - val_loss: 1.8535 - val_accuracy: 0.6834\n",
            "Epoch 414/500\n",
            "3/3 [==============================] - 2s 595ms/step - loss: 0.2021 - accuracy: 0.9342 - val_loss: 1.8797 - val_accuracy: 0.6837\n",
            "Epoch 415/500\n",
            "3/3 [==============================] - 2s 603ms/step - loss: 0.2004 - accuracy: 0.9349 - val_loss: 1.8436 - val_accuracy: 0.6799\n",
            "Epoch 416/500\n",
            "3/3 [==============================] - 2s 668ms/step - loss: 0.1999 - accuracy: 0.9355 - val_loss: 1.8261 - val_accuracy: 0.6817\n",
            "Epoch 417/500\n",
            "3/3 [==============================] - 2s 620ms/step - loss: 0.1986 - accuracy: 0.9363 - val_loss: 1.8629 - val_accuracy: 0.6847\n",
            "Epoch 418/500\n",
            "3/3 [==============================] - 2s 594ms/step - loss: 0.2012 - accuracy: 0.9347 - val_loss: 1.8857 - val_accuracy: 0.6847\n",
            "Epoch 419/500\n",
            "3/3 [==============================] - 2s 594ms/step - loss: 0.2276 - accuracy: 0.9354 - val_loss: 1.8310 - val_accuracy: 0.6832\n",
            "Epoch 420/500\n",
            "3/3 [==============================] - 2s 597ms/step - loss: 0.2013 - accuracy: 0.9340 - val_loss: 1.9003 - val_accuracy: 0.6794\n",
            "Epoch 421/500\n",
            "3/3 [==============================] - 2s 605ms/step - loss: 0.1987 - accuracy: 0.9355 - val_loss: 1.9736 - val_accuracy: 0.6789\n",
            "Epoch 422/500\n",
            "3/3 [==============================] - 2s 698ms/step - loss: 0.1995 - accuracy: 0.9347 - val_loss: 1.8504 - val_accuracy: 0.6781\n",
            "Epoch 423/500\n",
            "3/3 [==============================] - 2s 650ms/step - loss: 0.1947 - accuracy: 0.9365 - val_loss: 1.8973 - val_accuracy: 0.6801\n",
            "Epoch 424/500\n",
            "3/3 [==============================] - 2s 617ms/step - loss: 0.1938 - accuracy: 0.9368 - val_loss: 1.8360 - val_accuracy: 0.6773\n",
            "Epoch 425/500\n",
            "3/3 [==============================] - 3s 897ms/step - loss: 0.1952 - accuracy: 0.9371 - val_loss: 1.8502 - val_accuracy: 0.6824\n",
            "Epoch 426/500\n",
            "3/3 [==============================] - 2s 605ms/step - loss: 0.1905 - accuracy: 0.9382 - val_loss: 1.9035 - val_accuracy: 0.6778\n",
            "Epoch 427/500\n",
            "3/3 [==============================] - 2s 599ms/step - loss: 0.1911 - accuracy: 0.9380 - val_loss: 1.8184 - val_accuracy: 0.6776\n",
            "Epoch 428/500\n",
            "3/3 [==============================] - 2s 806ms/step - loss: 0.1898 - accuracy: 0.9395 - val_loss: 1.9033 - val_accuracy: 0.6819\n",
            "Epoch 429/500\n",
            "3/3 [==============================] - 2s 598ms/step - loss: 0.1896 - accuracy: 0.9394 - val_loss: 1.8283 - val_accuracy: 0.6822\n",
            "Epoch 430/500\n",
            "3/3 [==============================] - 2s 603ms/step - loss: 0.1894 - accuracy: 0.9392 - val_loss: 1.8626 - val_accuracy: 0.6804\n",
            "Epoch 431/500\n",
            "3/3 [==============================] - 2s 598ms/step - loss: 0.1878 - accuracy: 0.9396 - val_loss: 1.8196 - val_accuracy: 0.6801\n",
            "Epoch 432/500\n",
            "3/3 [==============================] - 2s 615ms/step - loss: 0.1885 - accuracy: 0.9400 - val_loss: 1.9015 - val_accuracy: 0.6819\n",
            "Epoch 433/500\n",
            "3/3 [==============================] - 2s 607ms/step - loss: 0.1909 - accuracy: 0.9395 - val_loss: 1.8611 - val_accuracy: 0.6796\n",
            "Epoch 434/500\n",
            "3/3 [==============================] - 2s 774ms/step - loss: 0.1907 - accuracy: 0.9385 - val_loss: 1.7996 - val_accuracy: 0.6809\n",
            "Epoch 435/500\n",
            "3/3 [==============================] - 2s 618ms/step - loss: 0.1905 - accuracy: 0.9378 - val_loss: 1.9166 - val_accuracy: 0.6801\n",
            "Epoch 436/500\n",
            "3/3 [==============================] - 2s 613ms/step - loss: 0.1929 - accuracy: 0.9360 - val_loss: 1.8045 - val_accuracy: 0.6829\n",
            "Epoch 437/500\n",
            "3/3 [==============================] - 2s 603ms/step - loss: 0.1901 - accuracy: 0.9368 - val_loss: 1.8911 - val_accuracy: 0.6794\n",
            "Epoch 438/500\n",
            "3/3 [==============================] - 2s 610ms/step - loss: 0.1863 - accuracy: 0.9394 - val_loss: 1.8954 - val_accuracy: 0.6824\n",
            "Epoch 439/500\n",
            "3/3 [==============================] - 2s 622ms/step - loss: 0.1920 - accuracy: 0.9388 - val_loss: 1.9339 - val_accuracy: 0.6814\n",
            "Epoch 440/500\n",
            "3/3 [==============================] - 2s 788ms/step - loss: 0.2187 - accuracy: 0.9372 - val_loss: 2.0020 - val_accuracy: 0.6796\n",
            "Epoch 441/500\n",
            "3/3 [==============================] - 2s 609ms/step - loss: 0.1935 - accuracy: 0.9350 - val_loss: 1.9304 - val_accuracy: 0.6834\n",
            "Epoch 442/500\n",
            "3/3 [==============================] - 2s 600ms/step - loss: 0.1919 - accuracy: 0.9371 - val_loss: 1.8499 - val_accuracy: 0.6771\n",
            "Epoch 443/500\n",
            "3/3 [==============================] - 2s 610ms/step - loss: 0.1906 - accuracy: 0.9376 - val_loss: 1.9370 - val_accuracy: 0.6824\n",
            "Epoch 444/500\n",
            "3/3 [==============================] - 2s 611ms/step - loss: 0.1852 - accuracy: 0.9385 - val_loss: 1.8864 - val_accuracy: 0.6786\n",
            "Epoch 445/500\n",
            "3/3 [==============================] - 2s 604ms/step - loss: 0.1823 - accuracy: 0.9417 - val_loss: 1.9272 - val_accuracy: 0.6817\n",
            "Epoch 446/500\n",
            "3/3 [==============================] - 2s 819ms/step - loss: 0.1832 - accuracy: 0.9398 - val_loss: 1.9098 - val_accuracy: 0.6799\n",
            "Epoch 447/500\n",
            "3/3 [==============================] - 2s 602ms/step - loss: 0.1810 - accuracy: 0.9422 - val_loss: 1.9066 - val_accuracy: 0.6832\n",
            "Epoch 448/500\n",
            "3/3 [==============================] - 2s 605ms/step - loss: 0.1806 - accuracy: 0.9417 - val_loss: 1.8939 - val_accuracy: 0.6832\n",
            "Epoch 449/500\n",
            "3/3 [==============================] - 2s 592ms/step - loss: 0.1788 - accuracy: 0.9424 - val_loss: 1.9044 - val_accuracy: 0.6817\n",
            "Epoch 450/500\n",
            "3/3 [==============================] - 2s 592ms/step - loss: 0.1791 - accuracy: 0.9427 - val_loss: 1.9158 - val_accuracy: 0.6809\n",
            "Epoch 451/500\n",
            "3/3 [==============================] - 2s 600ms/step - loss: 0.1809 - accuracy: 0.9430 - val_loss: 1.9449 - val_accuracy: 0.6811\n",
            "Epoch 452/500\n",
            "3/3 [==============================] - 2s 747ms/step - loss: 0.1794 - accuracy: 0.9429 - val_loss: 1.8761 - val_accuracy: 0.6817\n",
            "Epoch 453/500\n",
            "3/3 [==============================] - 2s 595ms/step - loss: 0.1814 - accuracy: 0.9439 - val_loss: 1.9370 - val_accuracy: 0.6796\n",
            "Epoch 454/500\n",
            "3/3 [==============================] - 2s 594ms/step - loss: 0.1784 - accuracy: 0.9434 - val_loss: 1.9184 - val_accuracy: 0.6806\n",
            "Epoch 455/500\n",
            "3/3 [==============================] - 2s 606ms/step - loss: 0.1766 - accuracy: 0.9426 - val_loss: 1.9454 - val_accuracy: 0.6809\n",
            "Epoch 456/500\n",
            "3/3 [==============================] - 2s 603ms/step - loss: 0.1756 - accuracy: 0.9443 - val_loss: 1.9240 - val_accuracy: 0.6801\n",
            "Epoch 457/500\n",
            "3/3 [==============================] - 2s 603ms/step - loss: 0.1761 - accuracy: 0.9439 - val_loss: 1.9898 - val_accuracy: 0.6827\n",
            "Epoch 458/500\n",
            "3/3 [==============================] - 2s 738ms/step - loss: 0.1787 - accuracy: 0.9436 - val_loss: 1.9434 - val_accuracy: 0.6837\n",
            "Epoch 459/500\n",
            "3/3 [==============================] - 2s 616ms/step - loss: 0.1878 - accuracy: 0.9404 - val_loss: 2.0360 - val_accuracy: 0.6794\n",
            "Epoch 460/500\n",
            "3/3 [==============================] - 2s 607ms/step - loss: 0.1769 - accuracy: 0.9409 - val_loss: 1.9879 - val_accuracy: 0.6791\n",
            "Epoch 461/500\n",
            "3/3 [==============================] - 2s 610ms/step - loss: 0.1806 - accuracy: 0.9413 - val_loss: 1.9967 - val_accuracy: 0.6809\n",
            "Epoch 462/500\n",
            "3/3 [==============================] - 2s 600ms/step - loss: 0.1749 - accuracy: 0.9420 - val_loss: 1.9233 - val_accuracy: 0.6801\n",
            "Epoch 463/500\n",
            "3/3 [==============================] - 2s 596ms/step - loss: 0.1791 - accuracy: 0.9425 - val_loss: 1.9204 - val_accuracy: 0.6786\n",
            "Epoch 464/500\n",
            "3/3 [==============================] - 2s 689ms/step - loss: 0.1759 - accuracy: 0.9428 - val_loss: 1.9620 - val_accuracy: 0.6817\n",
            "Epoch 465/500\n",
            "3/3 [==============================] - 2s 609ms/step - loss: 0.1754 - accuracy: 0.9436 - val_loss: 1.9650 - val_accuracy: 0.6778\n",
            "Epoch 466/500\n",
            "3/3 [==============================] - 2s 611ms/step - loss: 0.1740 - accuracy: 0.9445 - val_loss: 1.9638 - val_accuracy: 0.6832\n",
            "Epoch 467/500\n",
            "3/3 [==============================] - 2s 610ms/step - loss: 0.1740 - accuracy: 0.9440 - val_loss: 1.9476 - val_accuracy: 0.6789\n",
            "Epoch 468/500\n",
            "3/3 [==============================] - 2s 611ms/step - loss: 0.1802 - accuracy: 0.9436 - val_loss: 2.0792 - val_accuracy: 0.6827\n",
            "Epoch 469/500\n",
            "3/3 [==============================] - 2s 598ms/step - loss: 0.1777 - accuracy: 0.9424 - val_loss: 1.9828 - val_accuracy: 0.6811\n",
            "Epoch 470/500\n",
            "3/3 [==============================] - 2s 681ms/step - loss: 0.2026 - accuracy: 0.9408 - val_loss: 1.9257 - val_accuracy: 0.6832\n",
            "Epoch 471/500\n",
            "3/3 [==============================] - 2s 637ms/step - loss: 0.1772 - accuracy: 0.9394 - val_loss: 1.8988 - val_accuracy: 0.6796\n",
            "Epoch 472/500\n",
            "3/3 [==============================] - 2s 618ms/step - loss: 0.1788 - accuracy: 0.9422 - val_loss: 2.0089 - val_accuracy: 0.6811\n",
            "Epoch 473/500\n",
            "3/3 [==============================] - 2s 610ms/step - loss: 0.1783 - accuracy: 0.9423 - val_loss: 2.0061 - val_accuracy: 0.6847\n",
            "Epoch 474/500\n",
            "3/3 [==============================] - 2s 613ms/step - loss: 0.1740 - accuracy: 0.9420 - val_loss: 2.1096 - val_accuracy: 0.6786\n",
            "Epoch 475/500\n",
            "3/3 [==============================] - 2s 604ms/step - loss: 0.1725 - accuracy: 0.9423 - val_loss: 1.9813 - val_accuracy: 0.6796\n",
            "Epoch 476/500\n",
            "3/3 [==============================] - 2s 702ms/step - loss: 0.1723 - accuracy: 0.9425 - val_loss: 2.0698 - val_accuracy: 0.6809\n",
            "Epoch 477/500\n",
            "3/3 [==============================] - 2s 610ms/step - loss: 0.1720 - accuracy: 0.9425 - val_loss: 1.9647 - val_accuracy: 0.6806\n",
            "Epoch 478/500\n",
            "3/3 [==============================] - 2s 610ms/step - loss: 0.1726 - accuracy: 0.9445 - val_loss: 1.9803 - val_accuracy: 0.6847\n",
            "Epoch 479/500\n",
            "3/3 [==============================] - 2s 598ms/step - loss: 0.1730 - accuracy: 0.9443 - val_loss: 1.9845 - val_accuracy: 0.6756\n",
            "Epoch 480/500\n",
            "3/3 [==============================] - 2s 611ms/step - loss: 0.1703 - accuracy: 0.9458 - val_loss: 1.9331 - val_accuracy: 0.6842\n",
            "Epoch 481/500\n",
            "3/3 [==============================] - 2s 614ms/step - loss: 0.1694 - accuracy: 0.9447 - val_loss: 2.0064 - val_accuracy: 0.6819\n",
            "Epoch 482/500\n",
            "3/3 [==============================] - 2s 706ms/step - loss: 0.1675 - accuracy: 0.9467 - val_loss: 2.0332 - val_accuracy: 0.6814\n",
            "Epoch 483/500\n",
            "3/3 [==============================] - 2s 634ms/step - loss: 0.1673 - accuracy: 0.9464 - val_loss: 2.0085 - val_accuracy: 0.6809\n",
            "Epoch 484/500\n",
            "3/3 [==============================] - 2s 608ms/step - loss: 0.1670 - accuracy: 0.9466 - val_loss: 2.0531 - val_accuracy: 0.6794\n",
            "Epoch 485/500\n",
            "3/3 [==============================] - 2s 597ms/step - loss: 0.1679 - accuracy: 0.9467 - val_loss: 2.0844 - val_accuracy: 0.6824\n",
            "Epoch 486/500\n",
            "3/3 [==============================] - 2s 608ms/step - loss: 0.1671 - accuracy: 0.9476 - val_loss: 2.0809 - val_accuracy: 0.6809\n",
            "Epoch 487/500\n",
            "3/3 [==============================] - 2s 601ms/step - loss: 0.1642 - accuracy: 0.9481 - val_loss: 2.1131 - val_accuracy: 0.6799\n",
            "Epoch 488/500\n",
            "3/3 [==============================] - 2s 649ms/step - loss: 0.1630 - accuracy: 0.9476 - val_loss: 2.0294 - val_accuracy: 0.6809\n",
            "Epoch 489/500\n",
            "3/3 [==============================] - 2s 646ms/step - loss: 0.1624 - accuracy: 0.9490 - val_loss: 2.0988 - val_accuracy: 0.6806\n",
            "Epoch 490/500\n",
            "3/3 [==============================] - 2s 608ms/step - loss: 0.1638 - accuracy: 0.9487 - val_loss: 2.1095 - val_accuracy: 0.6806\n",
            "Epoch 491/500\n",
            "3/3 [==============================] - 2s 610ms/step - loss: 0.1594 - accuracy: 0.9491 - val_loss: 2.0738 - val_accuracy: 0.6809\n",
            "Epoch 492/500\n",
            "3/3 [==============================] - 2s 608ms/step - loss: 0.1611 - accuracy: 0.9484 - val_loss: 2.0576 - val_accuracy: 0.6758\n",
            "Epoch 493/500\n",
            "3/3 [==============================] - 2s 607ms/step - loss: 0.1615 - accuracy: 0.9479 - val_loss: 2.0608 - val_accuracy: 0.6834\n",
            "Epoch 494/500\n",
            "3/3 [==============================] - 2s 622ms/step - loss: 0.1612 - accuracy: 0.9483 - val_loss: 2.0403 - val_accuracy: 0.6778\n",
            "Epoch 495/500\n",
            "3/3 [==============================] - 3s 962ms/step - loss: 0.1638 - accuracy: 0.9499 - val_loss: 2.0879 - val_accuracy: 0.6819\n",
            "Epoch 496/500\n",
            "3/3 [==============================] - 2s 604ms/step - loss: 0.1643 - accuracy: 0.9488 - val_loss: 2.0213 - val_accuracy: 0.6791\n",
            "Epoch 497/500\n",
            "3/3 [==============================] - 2s 619ms/step - loss: 0.1595 - accuracy: 0.9484 - val_loss: 2.0826 - val_accuracy: 0.6791\n",
            "Epoch 498/500\n",
            "3/3 [==============================] - 2s 611ms/step - loss: 0.1615 - accuracy: 0.9482 - val_loss: 2.0231 - val_accuracy: 0.6824\n",
            "Epoch 499/500\n",
            "3/3 [==============================] - 2s 630ms/step - loss: 0.1584 - accuracy: 0.9490 - val_loss: 2.1031 - val_accuracy: 0.6796\n",
            "Epoch 500/500\n",
            "3/3 [==============================] - 2s 634ms/step - loss: 0.1589 - accuracy: 0.9480 - val_loss: 2.0422 - val_accuracy: 0.6796\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e700f4e84f0>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model.save('tam2eng.keras')\n"
      ],
      "metadata": {
        "id": "OWrLCxrJv3Ob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_inputs = model.input[0]\n",
        "encoder_outputs, state_h_enc, state_c_enc = model.layers[2].output  # LSTM 1\n",
        "encoder_states = [state_h_enc, state_c_enc]\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "decoder_inputs = model.input[1]\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_state_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "decoder_lstm = model.layers[3]  # LSTM 2\n",
        "decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
        "    decoder_inputs, initial_state=decoder_state_inputs)\n",
        "decoder_states = [state_h_dec, state_c_dec]\n",
        "decoder_dense = model.layers[4]  # Dense Layer\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = Model([decoder_inputs] + decoder_state_inputs, [decoder_outputs] + decoder_states)\n",
        "\n",
        "def decode_seq(input_seq):\n",
        "    # Encoder\n",
        "    state_value = encoder_model.predict(input_seq, verbose=0)\n",
        "\n",
        "    # Decoder\n",
        "    target_seq = np.zeros((1, 1, len(y_voc)))\n",
        "    target_seq[0, 0, target_tok_enc[\"\\t\"]] = 1.0\n",
        "    stop = False\n",
        "    decode_sent = \"\"\n",
        "    while not stop:\n",
        "        output_tok, h, c = decoder_model.predict([target_seq] + state_value, verbose=0)\n",
        "        sample_token_idx = np.argmax(output_tok[0, -1, :])\n",
        "        sample_char = target_tok_dec[sample_token_idx]\n",
        "        decode_sent += sample_char\n",
        "        if sample_char == \"\\n\" or len(decode_sent) > max_decoder:\n",
        "            stop = True\n",
        "        target_seq = np.zeros((1, 1, len(y_voc)))\n",
        "        target_seq[0, 0, sample_token_idx] = 1.0\n",
        "        state_value = [h, c]\n",
        "    return decode_sent\n",
        "\n",
        "for i in range(10):\n",
        "    input_seq = encoder_input_data[i: i+1]\n",
        "    d_seq = decode_seq(input_seq)\n",
        "    print(\"Input Seq : \", X_txt[i])\n",
        "    print(\"Output Seq : \", d_seq)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylUxz4yjwRam",
        "outputId": "1e75c7c3-8564-4b72-c10e-346f153fa1f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Seq :  நான் தூங்கினேன்.\n",
            "Output Seq :  I want to go han.\n",
            "\n",
            "Input Seq :  அமைதியாக இருங்கள்\n",
            "Output Seq :  I want to go abarread.\n",
            "\n",
            "Input Seq :  நான் நடப்பேன்.\n",
            "Output Seq :  I want to go abrare.\n",
            "\n",
            "Input Seq :  அவன் யார்?\n",
            "Output Seq :  I want to go abarread.\n",
            "\n",
            "Input Seq :  யாருக்குத் தெரியும்?\n",
            "Output Seq :  I want to go abartof.\n",
            "\n",
            "Input Seq :  அவள் சிரித்தாள்\n",
            "Output Seq :  I want to go abarread.\n",
            "\n",
            "Input Seq :  என்னிடம் பேசு\n",
            "Output Seq :  I want to go gon.\n",
            "\n",
            "Input Seq :  அவள் யார்?\n",
            "Output Seq :  I want to go abarread.\n",
            "\n",
            "Input Seq :  போய் தூங்கு\n",
            "Output Seq :  I want to go ang.\n",
            "\n",
            "Input Seq :  மழை பெய்யலாம்\n",
            "Output Seq :  I want to go abartof.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}